{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 1335,
     "status": "ok",
     "timestamp": 1602137718649,
     "user": {
      "displayName": "chetan vanapariya",
      "photoUrl": "",
      "userId": "09687593949013731715"
     },
     "user_tz": -330
    },
    "id": "N9kxqIqGnVXd"
   },
   "outputs": [],
   "source": [
    "file_path_ = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 3746,
     "status": "ok",
     "timestamp": 1602137723674,
     "user": {
      "displayName": "chetan vanapariya",
      "photoUrl": "",
      "userId": "09687593949013731715"
     },
     "user_tz": -330
    },
    "id": "KHJs59nnls9S"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.layers import Dense,Input,Activation\n",
    "from tensorflow.keras.models import Model\n",
    "import random as rn\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 2044,
     "status": "ok",
     "timestamp": 1602137728503,
     "user": {
      "displayName": "chetan vanapariya",
      "photoUrl": "",
      "userId": "09687593949013731715"
     },
     "user_tz": -330
    },
    "id": "QN1CXG_vnxQ9"
   },
   "outputs": [],
   "source": [
    "data_csv = pd.read_csv( file_path_ + \"data.csv\" , dtype={'label': 'int32' })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "executionInfo": {
     "elapsed": 1256,
     "status": "ok",
     "timestamp": 1602137736656,
     "user": {
      "displayName": "chetan vanapariya",
      "photoUrl": "",
      "userId": "09687593949013731715"
     },
     "user_tz": -330
    },
    "id": "O1kby-UaoNgQ",
    "outputId": "7b374667-53aa-442e-85cf-94876c09f7e6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.450564</td>\n",
       "      <td>1.074305</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         f1        f2  label\n",
       "0  0.450564  1.074305      0"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_csv.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1266,
     "status": "ok",
     "timestamp": 1602137961485,
     "user": {
      "displayName": "chetan vanapariya",
      "photoUrl": "",
      "userId": "09687593949013731715"
     },
     "user_tz": -330
    },
    "id": "Nd-QMIqbmmmM",
    "outputId": "b550aa91-5f62-4888-b760-653b6fa0ba48"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2.3.0', True)"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__  , tf.executing_eagerly()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kmKrE8RGr0KT"
   },
   "outputs": [],
   "source": [
    "# data_csv.drop( ['label'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1315,
     "status": "ok",
     "timestamp": 1602137783388,
     "user": {
      "displayName": "chetan vanapariya",
      "photoUrl": "",
      "userId": "09687593949013731715"
     },
     "user_tz": -330
    },
    "id": "_b78YP_br1kp",
    "outputId": "c0a5bc51-9f79-4d41-a1ef-190abeebfd0e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20000, 2), (20000,))"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data_csv\n",
    "data_y = data_csv['label'].values\n",
    "data_x = data_csv.drop( ['label'], axis=1).values\n",
    "data_x.shape , data_y.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 1223,
     "status": "ok",
     "timestamp": 1602137794998,
     "user": {
      "displayName": "chetan vanapariya",
      "photoUrl": "",
      "userId": "09687593949013731715"
     },
     "user_tz": -330
    },
    "id": "UQzp7vmlqjHD"
   },
   "outputs": [],
   "source": [
    "\n",
    "#data_y = data_csv['label'].values\n",
    "#data_x = data_csv.drop( ['label'], axis=1).values\n",
    "# split the data into test and train by maintaining same distribution of output varaible 'data_y' [stratify=data_y]\n",
    "X_train, X_test, Y_train, Y_test = train_test_split( data_x , data_y,stratify=data_y,test_size=0.20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1288,
     "status": "ok",
     "timestamp": 1602137817900,
     "user": {
      "displayName": "chetan vanapariya",
      "photoUrl": "",
      "userId": "09687593949013731715"
     },
     "user_tz": -330
    },
    "id": "yovxYY3ptm8q",
    "outputId": "ee46c715-e2cf-4ec8-c1d3-6a3e70e438d0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16000, 2), (16000,), (4000, 2), (4000,))"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, Y_train.shape, X_test.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2xk_WPlwwc5B"
   },
   "outputs": [],
   "source": [
    "class LossHistory(tf.keras.callbacks.Callback):\n",
    "    \n",
    "    def on_train_begin(self, logs={}):\n",
    "        ## on begin of training, we are creating a instance varible called history\n",
    "        ## it is a dict with keys [loss, acc, val_loss, val_acc]\n",
    "        self.history={'loss': [],'acc': [],'val_loss': [],'val_acc': []}\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        ## on end of each epoch, we will get logs and update the self.history dict\n",
    "        self.history['loss'].append(logs.get('loss'))\n",
    "        self.history['acc'].append(logs.get('acc'))\n",
    "        if logs.get('val_loss', -1) != -1:\n",
    "            self.history['val_loss'].append(logs.get('val_loss'))\n",
    "        if logs.get('val_acc', -1) != -1:\n",
    "            self.history['val_acc'].append(logs.get('val_acc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ToohB2QXGtXF"
   },
   "outputs": [],
   "source": [
    "class LearningRateCustom(tf.keras.callbacks.Callback):\n",
    "      def __init__(self, schedule, verbose=0):\n",
    "        super(LearningRateCustom, self).__init__()\n",
    "        self.schedule = schedule\n",
    "        self.verbose = verbose\n",
    "\n",
    "      def on_epoch_begin(self, epoch, logs=None):\n",
    "        if not hasattr(self.model.optimizer, 'lr'):\n",
    "          raise ValueError('Optimizer must have a \"lr\" attribute.')\n",
    "        try:  # new API\n",
    "          lr = float(K.get_value(self.model.optimizer.lr))\n",
    "          lr = self.schedule(epoch, lr)\n",
    "        except TypeError:  # Support for old API for backward compatibility\n",
    "          lr = self.schedule(epoch)\n",
    "        if not isinstance(lr, (ops.Tensor, float, np.float32, np.float64)):\n",
    "          raise ValueError('The output of the \"schedule\" function '\n",
    "                          'should be float.')\n",
    "        if isinstance(lr, ops.Tensor) and not lr.dtype.is_floating:\n",
    "          raise ValueError('The dtype of Tensor should be float')\n",
    "        K.set_value(self.model.optimizer.lr, K.get_value(lr))\n",
    "        if self.verbose > 0:\n",
    "          print('\\nEpoch %05d: LearningRateScheduler reducing learning '\n",
    "                'rate to %s.' % (epoch + 1, lr))\n",
    "\n",
    "      def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        logs['lr'] = K.get_value(self.model.optimizer.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3GnRAIB_6rRM"
   },
   "outputs": [],
   "source": [
    "#Custom Callback class\n",
    "class LearningRate(tf.keras.callbacks.LearningRateScheduler):\n",
    "    def __init__(self ,  schedule, verbose=0 ):\n",
    "        print(\"__init__ called\")\n",
    "        super(LearningRate, self ).__init__(  schedule, verbose )\n",
    "        self.schedule = schedule\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        ## on begin of training, we are creating a instance varible called history\n",
    "        ## it is a dict with keys [loss, acc, val_loss, val_acc]\n",
    "        print(\"on LearningRate called\")\n",
    "       # self.history_data={'loss': [],'acc': [],'val_loss': [],'val_acc': []}\n",
    "        self.initial_learningrate = 0.1\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        ## on end of each epoch, we will get logs and update the self.history dict\n",
    "        print(\"on_epoch_end called\")\n",
    "        print(\"logs : \" , logs )\n",
    "        self.schedule(epoch)\n",
    "        '''self.history_data['loss'].append(logs.get('loss'))\n",
    "        self.history_data['acc'].append(logs.get('accuracy'))\n",
    "        if logs.get('val_loss', -1) != -1:\n",
    "            self.history_data['val_loss'].append(logs.get('val_loss'))\n",
    "        if logs.get('val_accuracy', -1) != -1:\n",
    "            self.history_data['val_acc'].append(logs.get('val_accuracy'))\n",
    "\n",
    "        # getting any NaN values(either weigths or loss) while training, it has to terminate your training.\n",
    "        loss = logs.get('loss')\n",
    "        if loss is not None:\n",
    "            if np.isnan(loss) or np.isinf(loss):\n",
    "                print(\"Invalid loss and terminated at epoch {}\".format(epoch))\n",
    "                self.model.stop_training = True\n",
    "        '''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "executionInfo": {
     "elapsed": 1501,
     "status": "ok",
     "timestamp": 1602138071044,
     "user": {
      "displayName": "chetan vanapariya",
      "photoUrl": "",
      "userId": "09687593949013731715"
     },
     "user_tz": -330
    },
    "id": "cMbFVaWElBju"
   },
   "outputs": [],
   "source": [
    "#Custom Callback class\n",
    "class LossHistoryData(tf.keras.callbacks.Callback):\n",
    "    def __init__(self):\n",
    "        print(\"__init__ LossHistoryData\")\n",
    "\n",
    "    def on_train_begin(self, logs={}):\n",
    "        ## on begin of training, we are creating a instance varible called history_data\n",
    "        ## it is a dict with keys [loss, acc, val_loss, val_acc]\n",
    "        #print(\"on_train_begin called\")\n",
    "        self.history_data={'loss': [],'accuracy': [],'val_loss': [],'val_accuracy': []}\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        ## on end of each epoch, we will get logs and update the self.history_data dict\n",
    "        #print(\"on_epoch_end called\")\n",
    "        print(\"epoch:\" , epoch)\n",
    "        self.history_data['loss'].append(logs.get('loss'))\n",
    "        self.history_data['accuracy'].append(logs.get('accuracy'))\n",
    "        if logs.get('val_loss', -1) != -1:\n",
    "            self.history_data['val_loss'].append(logs.get('val_loss'))\n",
    "        if logs.get('val_accuracy', -1) != -1:\n",
    "            self.history_data['val_accuracy'].append(logs.get('val_accuracy'))\n",
    "\n",
    "        if (epoch > 2):\n",
    "          val_acc = self.history_data.get(\"val_accuracy\")\n",
    "          if ( ( val_acc[epoch-1] < val_acc[epoch-2] ) and  ( val_acc[epoch-2] < val_acc[epoch-3]) ):\n",
    "            #print(\"val_acc is not increased in last 2 epoch{}\".format(val_acc[epoch-3 : epoch]))\n",
    "            print(\"val_acc is not increased in last 2 epoch\")\n",
    "            self.model.stop_training = True\n",
    "        # getting any NaN values(either weigths or loss) while training, it has to terminate your training.\n",
    "        loss = logs.get('loss')\n",
    "        if loss is not None:\n",
    "            if np.isnan(loss) or np.isinf(loss):\n",
    "                print(\"Invalid loss and terminated at epoch {}\".format(epoch))\n",
    "                self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 1358,
     "status": "ok",
     "timestamp": 1602137844406,
     "user": {
      "displayName": "chetan vanapariya",
      "photoUrl": "",
      "userId": "09687593949013731715"
     },
     "user_tz": -330
    },
    "id": "ZEqrKKD02rdp"
   },
   "outputs": [],
   "source": [
    "#initial_learningrate=0.1\n",
    "def changeLearningRate(epoch , lr ):\n",
    "        #print( \"---> changeLearningRate : \" , epoch )\n",
    "        #initial_learningrate=0.01\n",
    "        val_loss = history_own_data.history_data.get(\"val_accuracy\")\n",
    "        #print(lr , \"--->v_acc\" , val_loss)\n",
    "        #lr = ( lr ) *(0.1)\n",
    "        if ( epoch > 1):\n",
    "          if ( (epoch % 3) == 0):\n",
    "            lr = ( lr ) *(0.05)\n",
    "          elif (val_loss[epoch-1] < val_loss[epoch-2]):\n",
    "            lr = ( lr ) *(0.1)\n",
    "        \n",
    "        return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 1257,
     "status": "ok",
     "timestamp": 1602137924282,
     "user": {
      "displayName": "chetan vanapariya",
      "photoUrl": "",
      "userId": "09687593949013731715"
     },
     "user_tz": -330
    },
    "id": "W07Gsifn4J9L"
   },
   "outputs": [],
   "source": [
    "#changeLearningRate(None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 1404,
     "status": "ok",
     "timestamp": 1602137931570,
     "user": {
      "displayName": "chetan vanapariya",
      "photoUrl": "",
      "userId": "09687593949013731715"
     },
     "user_tz": -330
    },
    "id": "4If3dqdJu5Ge"
   },
   "outputs": [],
   "source": [
    "Y_train = tf.keras.utils.to_categorical(Y_train, 10) \n",
    "Y_test = tf.keras.utils.to_categorical(Y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "executionInfo": {
     "elapsed": 1472,
     "status": "ok",
     "timestamp": 1602155519602,
     "user": {
      "displayName": "chetan vanapariya",
      "photoUrl": "",
      "userId": "09687593949013731715"
     },
     "user_tz": -330
    },
    "id": "LptSWRRy2lt2"
   },
   "outputs": [],
   "source": [
    "#from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_curve, auc , roc_auc_score\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "executionInfo": {
     "elapsed": 1268,
     "status": "ok",
     "timestamp": 1602147394523,
     "user": {
      "displayName": "chetan vanapariya",
      "photoUrl": "",
      "userId": "09687593949013731715"
     },
     "user_tz": -330
    },
    "id": "YN9CRQ_3zVsP"
   },
   "outputs": [],
   "source": [
    "class F1ScoreMetrics(tf.keras.callbacks.Callback):\n",
    "    def __init__(self , validation ):   \n",
    "        super(F1ScoreMetrics, self).__init__()\n",
    "        self.validation_data = validation    \n",
    "            \n",
    "        print('validation shape', len(self.validation_data[0]))\n",
    "        print(\"__init__F1ScoreMetrics\")\n",
    "\n",
    "    def on_train_begin(self, logs={}):        \n",
    "        self.val_f1score = []\n",
    "        self.auc_score = []\n",
    "        #self.val_recalls = []\n",
    "        #self.val_precisions = []\n",
    "     \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        #val_targ = self.validation[1]   \n",
    "        #val_predict = (np.asarray(self.model.predict(self.validation[0]))).round()        \n",
    "        val_x = self.validation_data[0]\n",
    "        val_y = self.validation_data[1]\n",
    "        val_predicted = (np.asarray(self.model.predict(val_x))).round() #(np.asarray()).round()\n",
    "        #print(\"val_predicted : \" , val_predicted.shape )\n",
    "        #print(\"val_y : \" , val_y.shape )\n",
    "        val_f1 = f1_score(val_y, val_predicted ,  average='micro' )\n",
    "        #val_recall = recall_score(val_targ, val_predict)         \n",
    "        #val_precision = precision_score(val_targ, val_predict)\n",
    "        #fpr,tpr,ths = roc_curve(np.mean(val_y, axis=1 ), np.mean( val_predicted , axis=1 ) )\n",
    "        auc_sc = roc_auc_score( val_y, val_predicted , average='micro')\n",
    "        #auc_sc = auc(fpr, tpr)\n",
    "        \n",
    "        self.val_f1score.append(round(val_f1, 6))\n",
    "        self.auc_score.append( auc_sc )\n",
    "        #self.val_recalls.append(round(val_recall, 6))\n",
    "        #self.val_precisions.append(round(val_precision, 6))\n",
    " \n",
    "        #print(f' — val_f1: {val_f1} — val_precision: {val_precision}, — val_recall: {val_recall}')\n",
    "        print(f' — val_f1score: {val_f1} -- AUC : {auc_sc}' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "executionInfo": {
     "elapsed": 1335,
     "status": "ok",
     "timestamp": 1602156595031,
     "user": {
      "displayName": "chetan vanapariya",
      "photoUrl": "",
      "userId": "09687593949013731715"
     },
     "user_tz": -330
    },
    "id": "R7tayZVO8cSA"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if (not os.path.isdir(\"/home/model_save\")):\n",
    "    print(os.makedirs(\"/home/model_save\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7361,
     "status": "ok",
     "timestamp": 1602156622705,
     "user": {
      "displayName": "chetan vanapariya",
      "photoUrl": "",
      "userId": "09687593949013731715"
     },
     "user_tz": -330
    },
    "id": "77t6dg_3lN6G",
    "outputId": "adbff847-f5c3-445f-c588-54d1520c08ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__init__ LossHistoryData\n",
      "validation shape 4000\n",
      "__init__F1ScoreMetrics\n",
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to 0.009999999776482582.\n",
      "Epoch 1/3\n",
      " 987/1000 [============================>.] - ETA: 0s - loss: 0.7676 - accuracy: 0.4987epoch: 0\n",
      " — val_f1score: 0.5 -- AUC : 0.7222222222222221\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.69575, saving model to /home/model_save/weights-01-0.5000.hdf5\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.7666 - accuracy: 0.4991 - val_loss: 0.6958 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to 0.009999999776482582.\n",
      "Epoch 2/3\n",
      " 993/1000 [============================>.] - ETA: 0s - loss: 0.6953 - accuracy: 0.5023epoch: 1\n",
      " — val_f1score: 0.5 -- AUC : 0.7222222222222221\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.69575 to 0.69451, saving model to /home/model_save/weights-02-0.5000.hdf5\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6954 - accuracy: 0.5019 - val_loss: 0.6945 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to 0.009999999776482582.\n",
      "Epoch 3/3\n",
      " 994/1000 [============================>.] - ETA: 0s - loss: 0.6949 - accuracy: 0.4984epoch: 2\n",
      " — val_f1score: 0.5 -- AUC : 0.7222222222222221\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.69451\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6948 - accuracy: 0.4986 - val_loss: 0.7029 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f99ced607f0>"
      ]
     },
     "execution_count": 111,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to work with callback\n",
    "\n",
    "#Input layer\n",
    "input_layer = Input(shape=(2,))\n",
    "\n",
    "#initializer = tf.keras.initializers.RandomUniform(minval=0., maxval=1.)\n",
    "#Dense hidden layer\n",
    "layer1 = Dense(50,activation='sigmoid',kernel_initializer=tf.keras.initializers.glorot_normal(seed=30))(input_layer)\n",
    "\n",
    "layer2 = Dense(40,activation='softmax',kernel_initializer=tf.keras.initializers.glorot_normal(seed=0))(layer1)\n",
    "layer3 = Dense(30,activation='softmax',kernel_initializer=tf.keras.initializers.glorot_normal(seed=0))(layer2)\n",
    "layer4 = Dense(20,activation='softmax',kernel_initializer=tf.keras.initializers.glorot_normal(seed=0))(layer3)\n",
    "layer5 = Dense(10,activation='softmax',kernel_initializer=tf.keras.initializers.glorot_normal(seed=0))(layer4)\n",
    "\n",
    "#output layer\n",
    "output = Dense(10,activation='softmax',kernel_initializer=tf.keras.initializers.glorot_normal(seed=0))(layer5)\n",
    "#Creating a model\n",
    "model = Model(inputs=input_layer,outputs=output)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(0.01)\n",
    "#opt = tf.keras.optimizers.SGD(learning_rate=0.1, momentum=0.9)\n",
    "#Callbacks\n",
    "history_own_data = LossHistoryData()\n",
    "#history_own_data = LossHistory()\n",
    "lrschedule = tf.keras.callbacks.LearningRateScheduler( changeLearningRate, verbose=1)\n",
    "#lrschedule = LearningRate(changeLearningRate , verbose=1)\n",
    "f1score = F1ScoreMetrics( validation=(X_test,Y_test))\n",
    "filepath=\"/home/model_save/weights-{epoch:02d}-{val_accuracy:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath=filepath, monitor='val_loss',  verbose=1, save_best_only=True, mode='auto')\n",
    "\n",
    "call_back_list = [history_own_data , lrschedule , f1score , checkpoint ]\n",
    "#optimizer = tf.keras.optimizers.Adam(0.01)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train,Y_train,epochs=3, validation_data=(X_test,Y_test), batch_size=16, callbacks= call_back_list )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2348,
     "status": "ok",
     "timestamp": 1602156693837,
     "user": {
      "displayName": "chetan vanapariya",
      "photoUrl": "",
      "userId": "09687593949013731715"
     },
     "user_tz": -330
    },
    "id": "o_kz8ipO79lJ",
    "outputId": "db566531-9481-4945-b42e-22efb0ca8fed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6942 - accuracy: 0.4945\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f99ceb5ca20>"
      ]
     },
     "execution_count": 113,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights('/home/model_save/weights-02-0.5000.hdf5')\n",
    "model.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1252,
     "status": "ok",
     "timestamp": 1602080709515,
     "user": {
      "displayName": "chetan vanapariya",
      "photoUrl": "",
      "userId": "09687593949013731715"
     },
     "user_tz": -330
    },
    "id": "LZu777HJRKio",
    "outputId": "40a4675b-8636-4a41-cae6-d771b89531c0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5024999976158142,\n",
       " 0.49300000071525574,\n",
       " 0.47350001335144043,\n",
       " 0.4737499952316284]"
      ]
     },
     "execution_count": 211,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_own_data.history_data.get(\"val_accuracy\")[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1645,
     "status": "ok",
     "timestamp": 1602069525081,
     "user": {
      "displayName": "chetan vanapariya",
      "photoUrl": "",
      "userId": "09687593949013731715"
     },
     "user_tz": -330
    },
    "id": "mowZM4XtvIRC",
    "outputId": "c0e0297f-40d5-442a-8cd0-f0322cbd9472"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acc': [0.5019375085830688, 0.5208125114440918, 0.6370000243186951],\n",
       " 'loss': [0.7112691402435303, 0.6974461674690247, 0.6364936232566833],\n",
       " 'val_acc': [0.5, 0.5137500166893005, 0.6667500138282776],\n",
       " 'val_loss': [0.69703209400177, 0.6818374395370483, 0.6041727662086487]}"
      ]
     },
     "execution_count": 48,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_own_data.history_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1169,
     "status": "ok",
     "timestamp": 1602069130083,
     "user": {
      "displayName": "chetan vanapariya",
      "photoUrl": "",
      "userId": "09687593949013731715"
     },
     "user_tz": -330
    },
    "id": "SkS55uOGwqC_",
    "outputId": "1d274d20-c61e-45df-91df-e606fbadefaf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acc': [None, None, None],\n",
       " 'loss': [0.7149479985237122, 0.6955052018165588, 0.6351665258407593],\n",
       " 'val_acc': [],\n",
       " 'val_loss': [0.6971844434738159, 0.6879738569259644, 0.6043661236763]}"
      ]
     },
     "execution_count": 35,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_own_data.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6292,
     "status": "ok",
     "timestamp": 1602156823302,
     "user": {
      "displayName": "chetan vanapariya",
      "photoUrl": "",
      "userId": "09687593949013731715"
     },
     "user_tz": -330
    },
    "id": "xVRP0DD1xosD",
    "outputId": "241e873c-eb76-422e-e51e-b00eb3b31c6e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__init__ LossHistoryData\n",
      "validation shape 4000\n",
      "__init__F1ScoreMetrics\n",
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to 0.009999999776482582.\n",
      "Epoch 1/3\n",
      " 983/1000 [============================>.] - ETA: 0s - loss: 1.2280 - accuracy: 0.4671epoch: 0\n",
      " — val_f1score: 0.6666666666666666 -- AUC : 0.9444444444444444\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.83023, saving model to /home/model_save/weights-01-0.5070.hdf5\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.2212 - accuracy: 0.4678 - val_loss: 0.8302 - val_accuracy: 0.5070\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to 0.009999999776482582.\n",
      "Epoch 2/3\n",
      " 955/1000 [===========================>..] - ETA: 0s - loss: 0.7777 - accuracy: 0.5086epoch: 1\n",
      " — val_f1score: 0.6666666666666666 -- AUC : 0.9444444444444444\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.83023 to 0.74643, saving model to /home/model_save/weights-02-0.5120.hdf5\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.7764 - accuracy: 0.5082 - val_loss: 0.7464 - val_accuracy: 0.5120\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to 0.009999999776482582.\n",
      "Epoch 3/3\n",
      " 969/1000 [============================>.] - ETA: 0s - loss: 0.7348 - accuracy: 0.5101epoch: 2\n",
      " — val_f1score: 0.6666666666666666 -- AUC : 0.9444444444444444\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.74643 to 0.72566, saving model to /home/model_save/weights-03-0.5120.hdf5\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.7345 - accuracy: 0.5101 - val_loss: 0.7257 - val_accuracy: 0.5120\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f99cedb30f0>"
      ]
     },
     "execution_count": 114,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to work with callback\n",
    "\n",
    "#Input layer\n",
    "input_layer1 = Input(shape=(2,))\n",
    "\n",
    "initializer = tf.keras.initializers.RandomUniform(minval=0., maxval=1.)\n",
    "#Dense hidden layer\n",
    "layer1_1 = Dense(50,activation='tanh',kernel_initializer=initializer)(input_layer1)\n",
    "layer1_2 = Dense(40,activation='tanh',kernel_initializer=initializer)(layer1_1)\n",
    "layer1_3 = Dense(30,activation='tanh',kernel_initializer=initializer)(layer1_2)\n",
    "layer1_4 = Dense(20,activation='tanh',kernel_initializer=initializer)(layer1_3)\n",
    "layer1_5 = Dense(10,activation='tanh',kernel_initializer=initializer)(layer1_4)\n",
    "#output layer\n",
    "output1 = Dense(10,activation='sigmoid',kernel_initializer=tf.keras.initializers.glorot_normal(seed=0))(layer1_5)\n",
    "#Creating a model\n",
    "model1 = Model(inputs=input_layer1,outputs=output1)\n",
    "\n",
    "#optimizer\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9)\n",
    "#Callbacks\n",
    "history_own_data1 = LossHistoryData()\n",
    "lrschedule = tf.keras.callbacks.LearningRateScheduler( changeLearningRate, verbose=1)\n",
    "f1score = F1ScoreMetrics( validation=(X_test,Y_test))\n",
    "filepath=\"/home/model_save/weights-{epoch:02d}-{val_accuracy:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath=filepath, monitor='val_loss',  verbose=1, save_best_only=True, mode='auto')\n",
    "\n",
    "call_back_list = [history_own_data1 , lrschedule , f1score , checkpoint]\n",
    "\n",
    "model1.compile(optimizer=optimizer, loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "model1.fit(X_train,Y_train,epochs=3, validation_data=(X_test,Y_test), batch_size=16, callbacks= call_back_list )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6103,
     "status": "ok",
     "timestamp": 1602156886180,
     "user": {
      "displayName": "chetan vanapariya",
      "photoUrl": "",
      "userId": "09687593949013731715"
     },
     "user_tz": -330
    },
    "id": "jO_6SYrE0tdy",
    "outputId": "fd084f0c-1f45-4557-adaf-abb896aac144"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__init__ LossHistoryData\n",
      "validation shape 4000\n",
      "__init__F1ScoreMetrics\n",
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to 0.009999999776482582.\n",
      "Epoch 1/3\n",
      " 957/1000 [===========================>..] - ETA: 0s - loss: 0.7129 - accuracy: 0.5895epoch: 0\n",
      " — val_f1score: 0.6666666666666666 -- AUC : 0.9444444444444444\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.69320, saving model to /home/model_save/weights-01-0.5850.hdf5\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.7121 - accuracy: 0.5897 - val_loss: 0.6932 - val_accuracy: 0.5850\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to 0.009999999776482582.\n",
      "Epoch 2/3\n",
      " 977/1000 [============================>.] - ETA: 0s - loss: 0.6931 - accuracy: 0.5621epoch: 1\n",
      " — val_f1score: 0.6666666666666666 -- AUC : 0.9444444444444444\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.69320 to 0.68993, saving model to /home/model_save/weights-02-0.5000.hdf5\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.6930 - accuracy: 0.5599 - val_loss: 0.6899 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to 0.009999999776482582.\n",
      "Epoch 3/3\n",
      " 970/1000 [============================>.] - ETA: 0s - loss: 0.6885 - accuracy: 0.5010epoch: 2\n",
      " — val_f1score: 0.6666666666666666 -- AUC : 0.9444444444444444\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.68993 to 0.68471, saving model to /home/model_save/weights-03-0.5000.hdf5\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.6885 - accuracy: 0.5000 - val_loss: 0.6847 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f99ce88d550>"
      ]
     },
     "execution_count": 115,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to work with callback\n",
    "\n",
    "#Input layer\n",
    "input_layer2 = Input(shape=(2,))\n",
    "\n",
    "initializer = tf.keras.initializers.he_uniform()\n",
    "#Dense hidden layer\n",
    "layer2_1 = Dense(50,activation='relu',kernel_initializer=initializer)(input_layer2)\n",
    "layer2_2 = Dense(40,activation='relu',kernel_initializer=initializer)(layer2_1)\n",
    "layer2_3 = Dense(30,activation='relu',kernel_initializer=initializer)(layer2_2)\n",
    "layer2_4 = Dense(20,activation='relu',kernel_initializer=initializer)(layer2_3)\n",
    "layer2_5 = Dense(10,activation='relu',kernel_initializer=initializer)(layer2_4)\n",
    "#output layer\n",
    "output2 = Dense(10,activation='sigmoid',kernel_initializer=tf.keras.initializers.glorot_normal(seed=0))(layer2_5)\n",
    "#Creating a model\n",
    "model2 = Model(inputs=input_layer2,outputs=output2)\n",
    "\n",
    "#optimizer\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9)\n",
    "#Callbacks\n",
    "history_own_data2 = LossHistoryData()\n",
    "lrschedule = tf.keras.callbacks.LearningRateScheduler( changeLearningRate, verbose=1)\n",
    "f1score = F1ScoreMetrics( validation=(X_test,Y_test))\n",
    "filepath=\"/home/model_save/weights-{epoch:02d}-{val_accuracy:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath=filepath, monitor='val_loss',  verbose=1, save_best_only=True, mode='auto')\n",
    "\n",
    "call_back_list = [history_own_data2 , lrschedule , f1score , checkpoint ]\n",
    "\n",
    "model2.compile(optimizer=optimizer, loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "model2.fit(X_train,Y_train,epochs=3, validation_data=(X_test,Y_test), batch_size=16, callbacks= call_back_list )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6182,
     "status": "ok",
     "timestamp": 1602156949870,
     "user": {
      "displayName": "chetan vanapariya",
      "photoUrl": "",
      "userId": "09687593949013731715"
     },
     "user_tz": -330
    },
    "id": "At_ge30l2nc9",
    "outputId": "39d29cef-195c-4db5-e174-eaf0f6286dad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__init__ LossHistoryData\n",
      "validation shape 4000\n",
      "__init__F1ScoreMetrics\n",
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to 0.009999999776482582.\n",
      "Epoch 1/3\n",
      " 993/1000 [============================>.] - ETA: 0s - loss: 0.7246 - accuracy: 0.6053epoch: 0\n",
      " — val_f1score: 0.6666666666666666 -- AUC : 0.9444444444444444\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.69320, saving model to /home/model_save/weights-01-0.6135.hdf5\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.7244 - accuracy: 0.6055 - val_loss: 0.6932 - val_accuracy: 0.6135\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to 0.009999999776482582.\n",
      "Epoch 2/3\n",
      " 993/1000 [============================>.] - ETA: 0s - loss: 0.6932 - accuracy: 0.6209epoch: 1\n",
      " — val_f1score: 0.6666666666666666 -- AUC : 0.9444444444444444\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.69320 to 0.69317, saving model to /home/model_save/weights-02-0.6160.hdf5\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.6932 - accuracy: 0.6207 - val_loss: 0.6932 - val_accuracy: 0.6160\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to 0.009999999776482582.\n",
      "Epoch 3/3\n",
      " 953/1000 [===========================>..] - ETA: 0s - loss: 0.6932 - accuracy: 0.6200epoch: 2\n",
      " — val_f1score: 0.6666666666666666 -- AUC : 0.9444444444444444\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.69317 to 0.69316, saving model to /home/model_save/weights-03-0.6148.hdf5\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.6210 - val_loss: 0.6932 - val_accuracy: 0.6148\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f99cb9beba8>"
      ]
     },
     "execution_count": 116,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to work with callback\n",
    "\n",
    "#Input layer\n",
    "input_layer3 = Input(shape=(2,))\n",
    "\n",
    "initializer = tf.keras.initializers.he_uniform()\n",
    "#Dense hidden layer\n",
    "layer3_1 = Dense(50,activation='relu',kernel_initializer=initializer)(input_layer3)\n",
    "layer3_2 = Dense(40,activation='relu',kernel_initializer=initializer)(layer3_1)\n",
    "layer3_3 = Dense(30,activation='relu',kernel_initializer=initializer)(layer3_2)\n",
    "layer3_4 = Dense(20,activation='relu',kernel_initializer=initializer)(layer3_3)\n",
    "layer3_5 = Dense(10,activation='relu',kernel_initializer=initializer)(layer3_4)\n",
    "#output layer\n",
    "output3 = Dense(10,activation='sigmoid',kernel_initializer=tf.keras.initializers.glorot_normal(seed=0))(layer3_5)\n",
    "#Creating a model\n",
    "model3 = Model(inputs=input_layer3,outputs=output3)\n",
    "\n",
    "#optimizer\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9)\n",
    "#Callbacks\n",
    "history_own_data3 = LossHistoryData()\n",
    "lrschedule = tf.keras.callbacks.LearningRateScheduler( changeLearningRate, verbose=1)\n",
    "f1score = F1ScoreMetrics( validation=(X_test,Y_test))\n",
    "filepath=\"/home/model_save/weights-{epoch:02d}-{val_accuracy:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath=filepath, monitor='val_loss',  verbose=1, save_best_only=True, mode='auto')\n",
    "\n",
    "call_back_list = [history_own_data3 , lrschedule , f1score , checkpoint ]\n",
    "\n",
    "model3.compile(optimizer=optimizer, loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "model3.fit(X_train,Y_train,epochs=3, validation_data=(X_test,Y_test), batch_size=16, callbacks= call_back_list )\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Call_Backs_Assignment_practice.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
