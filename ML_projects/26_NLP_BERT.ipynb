{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9"},"colab":{"provenance":[]},"gpuClass":"standard"},"cells":[{"cell_type":"markdown","metadata":{"id":"5el_8SqFqVAT"},"source":["\n","In this notebook, You will do amazon review classification with BERT."]},{"cell_type":"code","metadata":{"id":"wOtG4cf0qVAZ"},"source":["#all imports\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","import tensorflow_hub as hub\n","from tensorflow.keras.models import Model\n","\n","import re\n","import pickle\n","from sklearn.model_selection import train_test_split\n","\n","import random as rn\n","\n","from tensorflow.keras.layers import Input, Dense, Activation, Dropout,MaxPooling1D,Conv1D\n","#from tensorflow.keras.models import Model\n","import datetime\n","from sklearn.metrics import roc_auc_score\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"T813iMNMeWEK","outputId":"4356ba3d-48a7-4a21-b3d1-a7761f03c2ec","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["tf.__version__"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'2.8.2'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"aKphA7UWfQ9S","outputId":"3e83347f-5650-4925-bcf7-07dc45f30969","colab":{"base_uri":"https://localhost:8080/"}},"source":["tf.test.is_built_with_gpu_support()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"OcmiHdAJqVAi","outputId":"e12e28dc-68fe-4764-f47c-c83d64dddc7d","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["tf.test.gpu_device_name()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/device:GPU:0'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":5}]},{"cell_type":"markdown","metadata":{"id":"LBsay58AqVAo"},"source":["<font size=4>Grader function 1 </font>"]},{"cell_type":"code","metadata":{"id":"aTBvOKFeqVAq","outputId":"a1144e7f-3df9-4b25-a2bc-d83718d1519a","colab":{"base_uri":"https://localhost:8080/"}},"source":["def grader_tf_version():\n","    assert((tf.__version__)>'2')\n","    return True\n","grader_tf_version()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":7}]},{"cell_type":"markdown","metadata":{"id":"ZTWRqbrBqVAu"},"source":["<pre><font size=6>Part-1: Preprocessing</font></pre>"]},{"cell_type":"code","metadata":{"id":"B3csZKDrqVAv","outputId":"8b95442b-adff-4a42-e79c-f254bda14c7a","colab":{"base_uri":"https://localhost:8080/"}},"source":["#Read the dataset - Amazon fine food reviews\n","#reviews = pd.read_csv(r\"D:\\ML\\Internal DL\\NLP\\amazon-fine-food-reviews\\Reviews.csv\")\n","reviews_df = pd.read_csv(r\"/content/26_NLP_Transfer/Reviews.csv\")\n","#check the info of the dataset\n","reviews_df.info()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 568454 entries, 0 to 568453\n","Data columns (total 10 columns):\n"," #   Column                  Non-Null Count   Dtype \n","---  ------                  --------------   ----- \n"," 0   Id                      568454 non-null  int64 \n"," 1   ProductId               568454 non-null  object\n"," 2   UserId                  568454 non-null  object\n"," 3   ProfileName             568438 non-null  object\n"," 4   HelpfulnessNumerator    568454 non-null  int64 \n"," 5   HelpfulnessDenominator  568454 non-null  int64 \n"," 6   Score                   568454 non-null  int64 \n"," 7   Time                    568454 non-null  int64 \n"," 8   Summary                 568427 non-null  object\n"," 9   Text                    568454 non-null  object\n","dtypes: int64(5), object(5)\n","memory usage: 43.4+ MB\n"]}]},{"cell_type":"code","metadata":{"id":"KFwToAzHlOJh","outputId":"19ccda07-44a4-41be-870b-809775676fe2","colab":{"base_uri":"https://localhost:8080/"}},"source":["reviews_df.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(568454, 10)"]},"metadata":{"tags":[]},"execution_count":33}]},{"cell_type":"code","source":["reviews_df.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tjCaHcL4kEQQ","outputId":"3a04f893-9062-439c-e45d-5c5f7495515f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(568454, 10)"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"dFcz7QSHY0ET","outputId":"916ca301-c38b-4bbe-e368-19f85343a711","colab":{"base_uri":"https://localhost:8080/","height":179}},"source":["reviews_df.head(2)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Id</th>\n","      <th>ProductId</th>\n","      <th>UserId</th>\n","      <th>ProfileName</th>\n","      <th>HelpfulnessNumerator</th>\n","      <th>HelpfulnessDenominator</th>\n","      <th>Score</th>\n","      <th>Time</th>\n","      <th>Summary</th>\n","      <th>Text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>B001E4KFG0</td>\n","      <td>A3SGXH7AUHU8GW</td>\n","      <td>delmartian</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>5</td>\n","      <td>1303862400</td>\n","      <td>Good Quality Dog Food</td>\n","      <td>I have bought several of the Vitality canned d...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>B00813GRG4</td>\n","      <td>A1D87F6ZCVE5NK</td>\n","      <td>dll pa</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1346976000</td>\n","      <td>Not as Advertised</td>\n","      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Id  ...                                               Text\n","0   1  ...  I have bought several of the Vitality canned d...\n","1   2  ...  Product arrived labeled as Jumbo Salted Peanut...\n","\n","[2 rows x 10 columns]"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"xokNn7qZqVAz","outputId":"1de5fa15-ab32-4e89-80dc-3694e98bbe37","colab":{"base_uri":"https://localhost:8080/"}},"source":["#get only 2 columns - Text, Score\n","#drop the NAN values\n","\n","reviews = reviews_df.loc[ :, ['Text','Score']]\n","reviews = reviews.dropna(inplace=False)\n","#reviews = reviews.reset_index(drop=True)\n","reviews.shape   #.dropna(inplace=False).shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(568454, 2)"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"5GZt7pVkqVA4","outputId":"f45c29d0-edd0-4193-8ce2-003e48fc05ce","colab":{"base_uri":"https://localhost:8080/"}},"source":["#if score> 3, set score = 1\n","#if score<=2, set score = 0\n","#if score == 3, remove the rows. \n","\n","#443766 # 82007\n","reviews = reviews[ reviews['Score'] !=3 ]\n","print( reviews.shape )"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(525814, 2)\n"]}]},{"cell_type":"code","metadata":{"id":"wIFIRejRqXqN","outputId":"3b1fd3cf-65b3-484e-b2f6-48c1c6927871","colab":{"base_uri":"https://localhost:8080/"}},"source":["def set_binary_score( score ):\n","  if score > 3 :\n","    return 1\n","  elif score <= 2 :\n","    return 0\n","  else :\n","    return score\n","\n","#reviews['Score'] = reviews['Score'].apply( set_binary_score  )\n","reviews.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(525814, 2)"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","metadata":{"id":"g7_fQGQxuaz9","outputId":"7009e210-063d-41ce-8853-22019c2d794f","colab":{"base_uri":"https://localhost:8080/"}},"source":["print( reviews[ reviews['Score'] ==0 ].count() )\n","print( reviews[ reviews['Score'] ==1 ].count() )\n","#reviews.Score.value_counts()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Text     82037\n","Score    82037\n","dtype: int64\n","Text     443777\n","Score    443777\n","dtype: int64\n"]}]},{"cell_type":"markdown","metadata":{"id":"oVe8LlkrqVA6"},"source":["<font size=4>Grader function 2 </font>"]},{"cell_type":"code","metadata":{"id":"7mDXSiJpqVA7","outputId":"a9cb8baf-f495-4fcb-9621-40147ecb15a5","colab":{"base_uri":"https://localhost:8080/"}},"source":["def grader_reviews():\n","    temp_shape = (reviews.shape == (525814, 2)) and (reviews.Score.value_counts()[1]==443777)\n","    assert(temp_shape == True)\n","    return True\n","grader_reviews()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","metadata":{"id":"xYZ-UB9UqVA-"},"source":["def get_wordlen(x):\n","    return len(x.split())\n","reviews['len'] = reviews.Text.apply(get_wordlen)\n","reviews = reviews[reviews.len<50]\n","reviews = reviews.sample(n=100000, random_state=30)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CvldQriGqVBB"},"source":["#remove HTML from the Text column and save in the Text column only"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y1Rne5OVwe8F"},"source":["def decontracted(phrase):\n","    # specific\n","    phrase = re.sub(r\"won't\", \"will not\", phrase)\n","    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n","\n","    # general\n","    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n","    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n","    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n","    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n","    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n","    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n","    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n","    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n","    return phrase\n","\n","def text_preprocess( text_line ):\n","    processed_text = text_line\n","    \n","    processed_text = processed_text.replace('\\r', ' ')\n","    processed_text = processed_text.replace('\\n', ' ')\n","    processed_text = processed_text.replace('\\t', ' ')\n","    processed_text = processed_text.replace('\\\"', ' ')\n","    \n","    processed_text = decontracted( processed_text )\n","\n","    remove_tag_regex = re.compile(r'<[^>]+>')\n","    processed_text = remove_tag_regex.sub( ' ' , processed_text )\n","\n","    sp_char_regex = re.compile(r'[^a-zA-Z0-9]')\n","    processed_text = sp_char_regex.sub( ' ' , processed_text )\n","    processed_text = processed_text.lower()\n","\n","    return processed_text\n","\n","#reviews['Text'] = reviews['Text'].apply( text_preprocess )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1tB-6Jp3zlYK","outputId":"93118dc5-1b39-4f02-bc4b-2da924c74d82","colab":{"base_uri":"https://localhost:8080/"}},"source":["reviews.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(100000, 3)"]},"metadata":{},"execution_count":32}]},{"cell_type":"code","source":["reviews['Score'].value_counts()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Pkb09pUulrYP","outputId":"058a8418-341e-4a90-e614-4dfaa0a739c6"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1    87004\n","0    12996\n","Name: Score, dtype: int64"]},"metadata":{},"execution_count":33}]},{"cell_type":"code","metadata":{"id":"AhfN1s2mqVBD","outputId":"31dd9251-2c5f-4d9f-e3ee-d46e6f732560","colab":{"base_uri":"https://localhost:8080/","height":204}},"source":["#print head 5\n","reviews.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Text</th>\n","      <th>Score</th>\n","      <th>len</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>64117</th>\n","      <td>The tea was of great quality and it tasted lik...</td>\n","      <td>1</td>\n","      <td>30</td>\n","    </tr>\n","    <tr>\n","      <th>418112</th>\n","      <td>My cat loves this.  The pellets are nice and s...</td>\n","      <td>1</td>\n","      <td>31</td>\n","    </tr>\n","    <tr>\n","      <th>357829</th>\n","      <td>Great product. Does not completely get rid of ...</td>\n","      <td>1</td>\n","      <td>41</td>\n","    </tr>\n","    <tr>\n","      <th>175872</th>\n","      <td>This gum is my favorite!  I would advise every...</td>\n","      <td>1</td>\n","      <td>27</td>\n","    </tr>\n","    <tr>\n","      <th>178716</th>\n","      <td>I also found out about this product because of...</td>\n","      <td>1</td>\n","      <td>22</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                     Text  Score  len\n","64117   The tea was of great quality and it tasted lik...      1   30\n","418112  My cat loves this.  The pellets are nice and s...      1   31\n","357829  Great product. Does not completely get rid of ...      1   41\n","175872  This gum is my favorite!  I would advise every...      1   27\n","178716  I also found out about this product because of...      1   22"]},"metadata":{"tags":[]},"execution_count":47}]},{"cell_type":"code","source":["reviews[3:4].values"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WG68PD1oku8v","outputId":"15ccb82d-dec2-4c6d-a197-937743354e14"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([['these bars are so yummy  i was looking for a night snack and grabbed this out of my mom box from influenster and this hit the spot ',\n","        1, 27],\n","       ['my vodka tonics have never been so refreshing   i wish i would have ordered two cases now as my husband and i are going through far too much ',\n","        1, 28],\n","       ['i got the pineapple  mango and choco  my family liked the latter 2 the most  yummy coconut water if you are not looking for one that is not too sugary imo ',\n","        1, 31],\n","       ['when i bought the coffee maker  this was in the free samples   after using the samples my husband liked the donut coffee the best and so did i  i buy both the decaf and the regular k cup coffee people donut shop   love it ',\n","        1, 43],\n","       ['we use this on fish also  it is a great seasoning and is a low cal solution to a great meal ',\n","        1, 21],\n","       ['is a good product and taste much better than the small squares that are sold under another name   good candy',\n","        1, 20],\n","       ['i have a bichon and i thought this would entertain him for at least 15 minutes  but it did not  he solved it quickly  within 5 minutes and looked at me as if to say  that is all ',\n","        0, 36],\n","       ['gloria jeans seems to make the best tasting hazelnut  i tried all the rest and for some reason this one tastes the most natural to me ',\n","        1, 26],\n","       ['my dogs love these dogs cookies   i can not imagine buying anything else  i love the price and the free shipping   life is good ',\n","        1, 23],\n","       ['product was very easy to use even for a first timer  great quality and would recommend this product for novice or experts ',\n","        1, 22]], dtype=object)"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"XJ8O-_9b0h-S","outputId":"26449ba6-45ab-4323-d285-ed5d8b7b7a93","colab":{"base_uri":"https://localhost:8080/","height":377}},"source":["reviews[30:40].values"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[\"I have never been a huge coffee fan. However, my mother purchased this little machine and talked me into trying the Latte Macciato. No Coffee Shop has a better one and I like most of the other products, too (as a usually non-coffee drinker!). The little Dolche Guesto Machine is super easy to use and prepares a really good Coffee/Latte/Cappuccino/etc in less than a minute (if water is heated up). I would recommend the Dolce Gusto to anyone. Too good for the price and I'am getting one myself! :)\",\n","        1],\n","       ['This offer is a great price and a great taste, thanks Amazon for selling this product.  Staral',\n","        1],\n","       [\"McCann's Instant Oatmeal is great if you must have your oatmeal but can only scrape together two or three minutes to prepare it. There is no escaping the fact, however, that even the best instant oatmeal is nowhere near as good as even a store brand of oatmeal requiring stovetop preparation.  Still, the McCann's is as good as it gets for instant oatmeal. It's even better than the organic, all-natural brands I have tried.  All the varieties in the McCann's variety pack taste good.  It can be prepared in the microwave or by adding boiling water so it is convenient in the extreme when time is an issue.  McCann's use of actual cane sugar instead of high fructose corn syrup helped me decide to buy this product.  Real sugar tastes better and is not as harmful as the other stuff. One thing I do not like, though, is McCann's use of thickeners.  Oats plus water plus heat should make a creamy, tasty oatmeal without the need for guar gum. But this is a convenience product.  Maybe the guar gum is why, after sitting in the bowl a while, the instant McCann's becomes too thick and gluey.\",\n","        1],\n","       [\"This is a good instant oatmeal from the best oatmeal brand.  It uses cane sugar instead of high fructouse corn syrup, so not only does it have a better sweetness, but some doctors now say that this form of sugar is better for you.  Great on a cold morning when you don't have time to make McCann's Steel Cut Oats.  The apple cinnamon is the best but the maple and brown sugar or the regular are good too.  Plus they don't require doctoring to actually tell the three flavors apart.\",\n","        1],\n","       [\"Instant oatmeal can become soggy the minute the water hits the bowl. McCann's Instant Oatmeal holds its texture, has excellent flavor, and is good for you all at the same time. McCann's regular oat meal is excellent, too, but may take a bit longer to prepare than most have time for in the morning. This is the best instant brand I've ever eaten, and a very close second to the non-instant variety.  McCann's Instant Irish Oatmeal, Variety Pack of Regular, Apples & Cinnamon, and Maple & Brown Sugar, 10-Count Boxes (Pack of 6)\",\n","        1],\n","       [\"McCann's Instant Irish Oatmeal, Variety Pack of Regular, Apples & Cinnamon, and Maple & Brown Sugar, 10-Count Boxes (Pack of 6)  I'm a fan of the McCann's steel-cut oats, so I thought I'd give the instant variety a try. I found it to be a hardy meal, not too sweet, and great for folks like me (post-bariatric surgery) who need food that is palatable, easily digestible, with fiber but won't make you bloat.\",\n","        1],\n","       [\"For those of us with celiac disease this product is a lifesaver and what could be better than getting it at almost half the price of the grocery or health food store!  I love McCann's instant oatmeal - all flavors!!!  Thanks, Abby\",\n","        1],\n","       [\"What else do you need to know? Oatmeal, instant (make it with a half cup of low-fat milk and add raisins;nuke for 90 seconds). More expensive than Kroger store brand oatmeal and maybe a little tastier or better texture or something. It's still just oatmeal. Mmm, convenient!\",\n","        1],\n","       ['I WAS VISITING MY FRIEND NATE THE OTHER MORNING FOR COFFEE , HE CAME OUT OF HIS STORAGE ROOM WITH ( A PACKET OF McCANNS INSTANT IRISH OATMEAL .) HE SUGGESTED THAT I TRY IT FOR MY OWN USE ,IN MY STASH . SOMETIMES NATE DOSE NOT GIVE YOU A CHANCE TO SAY NO , SO I ENDED UP TRYING THE APPLE AND CINN . FOUND IT TO BE VERY TASTEFULL WHEN MADE WITH WATER OR POWDERED MILK . IT GOES GOOD WITH O.J. AND COFFEE AND A SLICE OF TOAST AND YOUR READY TO TAKE ON THE WORLD...OR THE DAY AT LEAST..  JERRY REITH...',\n","        1],\n","       [\"I ordered this for my wife as it was reccomended by our daughter.  She has this almost every morning and likes all flavors.  She's happy, I'm happy!!!  McCANN'S Instant Irish Oatmeal, Variety Pack of Regular, Apples & Cinnamon, and Maple & Brown Sugar, 10-Count Boxes (Pack of 6) \",\n","        1]], dtype=object)"]},"metadata":{"tags":[]},"execution_count":112}]},{"cell_type":"code","metadata":{"id":"gkz_Knbs46Tm"},"source":["#import pickle\n","#from sklearn.model_selection import train_test_split"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NsYDd3okqVBF","outputId":"b3b62047-4607-439f-bb52-ccb90b11f89e","colab":{"base_uri":"https://localhost:8080/"}},"source":["#split the data into train and test data(20%) with Stratify sampling, random state 33, \n","\n","X_train , X_test , y_train , y_test = train_test_split( reviews['Text'].values ,\n","                                                       reviews['Score'].values ,\n","                                                       test_size=0.20, stratify= reviews['Score'].values , random_state=33 )\n","\n","X_train.shape , X_test.shape , y_train.shape , y_test.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((80000,), (20000,), (80000,), (20000,))"]},"metadata":{},"execution_count":23}]},{"cell_type":"code","source":["X_train[0:1]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rjWeFRWCk-jf","outputId":"aa2162ca-6137-477d-8d5d-f5683da278e5"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array(['i had never tried this brand before  so i was worried about the quality   it tasted great   a very nice smooth rich full flavor   its my new favoret '],\n","      dtype=object)"]},"metadata":{},"execution_count":24}]},{"cell_type":"code","metadata":{"id":"-Q6OAcrOqVBI"},"source":["#plot bar graphs of y_train and y_test"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Up-z5boWqVBK"},"source":["#saving to disk. if we need, we can load preprocessed data directly. \n","#reviews.to_csv( dir_path + 'preprocessed_1.csv', index=False)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bBtqNGN9qVBM"},"source":["<pre><font size=6>Part-2: Creating BERT Model</font> \n","\n","If you want to know more about BERT, You can watch live sessions on Transformers and BERt. \n","we will strongly recommend you to read <a href=\"https://jalammar.github.io/illustrated-transformer/\">Transformers</a>, <a href=\"https://arxiv.org/abs/1810.04805\">BERT Paper</a> and, <a href=\"https://jalammar.github.io/a-visual-guide-to-using-bert-for-the-first-time/\">This blog</a>.\n","\n","\n","For this assignment, we are using <a href=\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1\">BERT uncased Base model</a>. \n","It uses L=12 hidden layers (i.e., Transformer blocks), a hidden size of H=768, and A=12 attention heads. </pre>"]},{"cell_type":"code","metadata":{"id":"i8xd2HejqVBN"},"source":["## Loading the Pretrained Model from tensorflow HUB\n","tf.keras.backend.clear_session()\n","\n","# maximum length of a seq in the data we have, for now i am making it as 55. You can change this\n","max_seq_length = 55\n","\n","#BERT takes 3 inputs\n","\n","#this is input words. Sequence of words represented as integers\n","input_word_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32, name=\"input_word_ids\")\n","\n","#mask vector if you are padding anything\n","input_mask = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32, name=\"input_mask\")\n","\n","#segment vectors. If you are giving only one sentence for the classification, total seg vector is 0. \n","#If you are giving two sentenced with [sep] token separated, first seq segment vectors are zeros and \n","#second seq segment vector are 1's\n","segment_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32, name=\"segment_ids\")\n","\n","#bert layer \n","bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1\", trainable=False)\n","pooled_output, sequence_output = bert_layer([input_word_ids, input_mask, segment_ids])\n","\n","#Bert model\n","#We are using only pooled output not sequence out. \n","#If you want to know about those, please read https://www.kaggle.com/questions-and-answers/86510\n","bert_model = Model(inputs=[input_word_ids, input_mask, segment_ids], outputs=pooled_output)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lQJsjg6fqVBQ","outputId":"77dff397-ad9a-4149-9a76-ddcdf798ffd5","colab":{"base_uri":"https://localhost:8080/"}},"source":["bert_model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_word_ids (InputLayer)    [(None, 55)]         0           []                               \n","                                                                                                  \n"," input_mask (InputLayer)        [(None, 55)]         0           []                               \n","                                                                                                  \n"," segment_ids (InputLayer)       [(None, 55)]         0           []                               \n","                                                                                                  \n"," keras_layer (KerasLayer)       [(None, 768),        109482241   ['input_word_ids[0][0]',         \n","                                 (None, 55, 768)]                 'input_mask[0][0]',             \n","                                                                  'segment_ids[0][0]']            \n","                                                                                                  \n","==================================================================================================\n","Total params: 109,482,241\n","Trainable params: 0\n","Non-trainable params: 109,482,241\n","__________________________________________________________________________________________________\n"]}]},{"cell_type":"code","source":["#bert_model.get_layer('keras_layer').layer()\n","#bert_model.layers[3]._layers\n","#bert_model.layers[0].layers()\n"],"metadata":{"id":"eD1t-WPsBOBv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#bert_layer.summary()"],"metadata":{"id":"Hmp3EAkN1wZS"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"w3z0OMA5qVBS","outputId":"a7ffb34b-2a25-4c02-a1ab-79427582a304","colab":{"base_uri":"https://localhost:8080/"}},"source":["bert_model.output"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<KerasTensor: shape=(None, 768) dtype=float32 (created by layer 'keras_layer')>"]},"metadata":{},"execution_count":37}]},{"cell_type":"code","source":["'''\n","def build_classifier_model_1():\n","  text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n","  preprocessing_layer = hub.KerasLayer(tfhub_handle_preprocess, name='preprocessing')\n","  encoder_inputs = preprocessing_layer(text_input)\n","  encoder = hub.KerasLayer(tfhub_handle_encoder, trainable=True, name='BERT_encoder')\n","  outputs = encoder(encoder_inputs)\n","  net = outputs['pooled_output']\n","  net = tf.keras.layers.Dropout(0.1)(net)\n","  net = tf.keras.layers.Dense(1, activation=None, name='classifier')(net)\n","  return tf.keras.Model(text_input, net)\n","'''\n"],"metadata":{"id":"oVXbHPr5rAEx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ewv4hFCsqVBU"},"source":["<pre><font size=6>Part-3: Tokenization</font></pre>"]},{"cell_type":"code","metadata":{"id":"tX3VEFjiqVBU"},"source":["#getting Vocab file\n","vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n","do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y_iPwa99qVBW"},"source":["#import tokenization - We have given tokenization.py file"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RR55AXu8-1FN"},"source":["'''\n","import pickle\n","'''\n","import sys\n","sys.path.append('/content/26_NLP_Transfer')\n","from tokenization import FullTokenizer\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_4KF3D9N_Elz"},"source":["#from tokenization import FullTokenizer"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"guJMLJ8bqVBY"},"source":["# Create tokenizer \" Instantiate FullTokenizer\" \n","# name must be \"tokenizer\"\n","# the FullTokenizer takes two parameters 1. vocab_file and 2. do_lower_case \n","# we have created these in the above cell ex: FullTokenizer(vocab_file, do_lower_case )\n","# please check the \"tokenization.py\" file the complete implementation"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CUfsrCn9CrjG"},"source":["tokenizer = FullTokenizer(vocab_file, do_lower_case )"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KKkGLhR-qVBd"},"source":["<font size=4>Grader function 3 </font>"]},{"cell_type":"code","metadata":{"id":"2CPu850xqVBe","outputId":"9fbc1c49-ed90-4445-8ac6-cc67fc4bbd44","colab":{"base_uri":"https://localhost:8080/"}},"source":["#it has to give no error \n","def grader_tokenize(tokenizer):\n","    out = False\n","    try:\n","        out=('[CLS]' in tokenizer.vocab) and ('[SEP]' in tokenizer.vocab)\n","    except:\n","        out = False\n","    assert(out==True)\n","    return out\n","grader_tokenize(tokenizer)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":42}]},{"cell_type":"code","metadata":{"id":"9crhPylQqVBg"},"source":["# Create train and test tokens (X_train_tokens, X_test_tokens) from (X_train, X_test) using Tokenizer and \n","\n","# add '[CLS]' at start of the Tokens and '[SEP]' at the end of the tokens. \n","\n","# maximum number of tokens is 55(We already given this to BERT layer above) so shape is (None, 55)\n","\n","# if it is less than 55, add '[PAD]' token else truncate the tokens length.(similar to padding)\n","\n","# Based on padding, create the mask for Train and Test ( 1 for real token, 0 for '[PAD]'), \n","# it will also same shape as input tokens (None, 55) save those in X_train_mask, X_test_mask\n","\n","# Create a segment input for train and test. We are using only one sentence so all zeros. This shape will also (None, 55)\n","\n","# type of all the above arrays should be numpy arrays\n","\n","# after execution of this cell, you have to get \n","# X_train_tokens, X_train_mask, X_train_segment\n","# X_test_tokens, X_test_mask, X_test_segment"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4Cp5H3L9G_97"},"source":["#reviews['Text'].tolist()\n","#X_train_tokens , X_train_mask, X_train_segment = [] , [] , []\n","#X_train_tokens[1]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gbh-T_cbDVlT"},"source":["\n","X_train_tokens , X_train_mask, X_train_segment = [] , [] , []\n","\n","for i in range(X_train.shape[0]):\n","    \n","    tokens = tokenizer.tokenize( ( X_train[i] ) )\n","    tokens = tokens[ 0 : ( max_seq_length - 2 )]\n","    tokens = ['[CLS]',*tokens,'[SEP]']\n","\n","    #word to integer\n","    X_train_tokens.append( np.array( tokenizer.convert_tokens_to_ids(tokens) +  [0]*( max_seq_length - len(tokens))  ) )\n","    \n","    # mask\n","    X_train_mask.append( np.array([1]*len(tokens) + [0]*( max_seq_length - len(tokens))))\n","    \n","    #segment\n","    X_train_segment.append(np.array( [0]*( max_seq_length )))\n","\n","X_train_tokens = np.array( X_train_tokens )\n","X_train_mask = np.array( X_train_mask )\n","X_train_segment = np.array( X_train_segment ) \n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"j2VsJFAOHV7G"},"source":["#np.array( X_train ).tolist()\n","\n","X_test_tokens, X_test_mask, X_test_segment = [] , [] , []\n","\n","for i in range(X_test.shape[0]):\n","    \n","    tokens = tokenizer.tokenize( ( X_test[i] ) )\n","    tokens = tokens[ 0 : ( max_seq_length - 2 )]\n","    tokens = ['[CLS]',*tokens,'[SEP]']\n","    \n","    X_test_tokens.append( np.array( tokenizer.convert_tokens_to_ids(tokens) +  [0]*( max_seq_length - len(tokens))  ) )\n","    \n","    X_test_mask.append( np.array([1]*len(tokens) + [0]*( max_seq_length - len(tokens))))\n","    \n","    X_test_segment.append(np.array( [0]*( max_seq_length )))\n","\n","X_test_tokens = np.array( X_test_tokens )\n","X_test_mask = np.array( X_test_mask )\n","X_test_segment = np.array( X_test_segment )\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3HZ0Jx5EGbwQ","outputId":"fefb2088-9dd6-4b40-e587-fe647d787f91","colab":{"base_uri":"https://localhost:8080/"}},"source":["X_train_tokens.shape , X_train_mask.shape , X_train_segment.shape , \\\n","X_test_tokens.shape , X_test_mask.shape , X_test_segment.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((80000, 55), (80000, 55), (80000, 55), (20000, 55), (20000, 55), (20000, 55))"]},"metadata":{"tags":[]},"execution_count":130}]},{"cell_type":"code","source":["X_train_tokens[0:1] , X_train_mask[0:1] , X_train_segment[0:1]\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q9YuX8Yfw6y2","outputId":"6ca1c263-6d67-46a7-b84e-84806686f216"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(array([[  101,  1045,  2018,  2196,  2699,  2023,  4435,  2077,  2061,\n","          1045,  2001,  5191,  2055,  1996,  3737,  2009, 12595,  2307,\n","          1037,  2200,  3835,  5744,  4138,  2440, 14894,  2049,  2026,\n","          2047,  5684,  3388,   102,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0]]),\n"," array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]),\n"," array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]))"]},"metadata":{},"execution_count":46}]},{"cell_type":"markdown","metadata":{"id":"kv1-t4OjqVBj"},"source":["#### Example\n","<img src='https://i.imgur.com/5AhhmgU.png'>"]},{"cell_type":"code","metadata":{"id":"dxhggBxwqVBj"},"source":["#import pickle"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7oDT3j0hWmgL"},"source":["data_path = '/content/data/'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xF0idMRDqVBm"},"source":["##save all your results to disk so that, no need to run all again. \n","#pickle.dump((X_train, X_train_tokens, X_train_mask, X_train_segment, y_train),open( data_path + 'train_data_1.pkl','wb'))\n","#pickle.dump((X_test, X_test_tokens, X_test_mask, X_test_segment, y_test),open( data_path + 'test_data_1.pkl','wb'))\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Leu1URGzqVBo"},"source":["#you can load from disk\n","X_train, X_train_tokens, X_train_mask, X_train_segment, y_train = pickle.load(open( data_path + \"train_data_1.pkl\", 'rb')) \n","X_test, X_test_tokens, X_test_mask, X_test_segment, y_test = pickle.load(open( data_path + \"test_data_1.pkl\", 'rb'))\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9RDpvNmRTBKH","outputId":"cf9433dc-e93b-4612-a007-62dbfbbee76e","colab":{"base_uri":"https://localhost:8080/"}},"source":["#max_seq_length = 55\n","X_train_tokens.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(80000, 55)"]},"metadata":{},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"sjPv8VkJqVBr"},"source":["<font size=4>Grader function 4 </font>"]},{"cell_type":"code","metadata":{"id":"qekHJgmdqVBs","outputId":"84c6fd53-05e2-44de-b504-67bca831f349","colab":{"base_uri":"https://localhost:8080/"}},"source":["def grader_alltokens_train():\n","    out = False\n","    \n","    if type(X_train_tokens) == np.ndarray:\n","        \n","        temp_shapes = (X_train_tokens.shape[1]==max_seq_length) and (X_train_mask.shape[1]==max_seq_length) and \\\n","        (X_train_segment.shape[1]==max_seq_length)\n","        \n","        segment_temp = not np.any(X_train_segment)\n","        \n","        mask_temp = np.sum(X_train_mask==0) == np.sum(X_train_tokens==0)\n","        \n","        no_cls = np.sum(X_train_tokens==tokenizer.vocab['[CLS]'])==X_train_tokens.shape[0]\n","        \n","        no_sep = np.sum(X_train_tokens==tokenizer.vocab['[SEP]'])==X_train_tokens.shape[0]\n","        \n","        out = temp_shapes and segment_temp and mask_temp and no_cls and no_sep\n","      \n","    else:\n","        print('Type of all above token arrays should be numpy array not list')\n","        out = False\n","    assert(out==True)\n","    return out\n","\n","grader_alltokens_train()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":54}]},{"cell_type":"markdown","metadata":{"id":"KnvC6X_wqVBu"},"source":["<font size=4>Grader function 5 </font>"]},{"cell_type":"code","metadata":{"id":"Av4SRMPSqVBv","outputId":"01293fa5-16de-4bfc-8ba3-6352547b04b6","colab":{"base_uri":"https://localhost:8080/"}},"source":["def grader_alltokens_test():\n","    out = False\n","    if type(X_test_tokens) == np.ndarray:\n","        \n","        temp_shapes = (X_test_tokens.shape[1]==max_seq_length) and (X_test_mask.shape[1]==max_seq_length) and \\\n","        (X_test_segment.shape[1]==max_seq_length)\n","        \n","        segment_temp = not np.any(X_test_segment)\n","        \n","        mask_temp = np.sum(X_test_mask==0) == np.sum(X_test_tokens==0)\n","        \n","        no_cls = np.sum(X_test_tokens==tokenizer.vocab['[CLS]'])==X_test_tokens.shape[0]\n","        \n","        no_sep = np.sum(X_test_tokens==tokenizer.vocab['[SEP]'])==X_test_tokens.shape[0]\n","        \n","        out = temp_shapes and segment_temp and mask_temp and no_cls and no_sep\n","      \n","    else:\n","        print('Type of all above token arrays should be numpy array not list')\n","        out = False\n","    assert(out==True)\n","    return out\n","grader_alltokens_test()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":55}]},{"cell_type":"markdown","metadata":{"id":"SEj-Eua5qVBx"},"source":["<pre><font size=6>Part-4: Getting Embeddings from BERT Model</font>\n","We already created the BERT model in the part-2 and input data in the part-3. \n","We will utlize those two and will get the embeddings for each sentence in the \n","Train and test data.</pre>"]},{"cell_type":"code","metadata":{"id":"QwOVgQFDqVBy","outputId":"d584f3f6-d72c-480c-913b-9f71bc3f5d48","colab":{"base_uri":"https://localhost:8080/"}},"source":["bert_model.input"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[<KerasTensor: shape=(None, 55) dtype=int32 (created by layer 'input_word_ids')>,\n"," <KerasTensor: shape=(None, 55) dtype=int32 (created by layer 'input_mask')>,\n"," <KerasTensor: shape=(None, 55) dtype=int32 (created by layer 'segment_ids')>]"]},"metadata":{},"execution_count":56}]},{"cell_type":"code","metadata":{"id":"ZcpkQq1OqVB0","outputId":"a013329a-f300-495b-aa05-e5edc38c78f8","colab":{"base_uri":"https://localhost:8080/"}},"source":["bert_model.output"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<KerasTensor: shape=(None, 768) dtype=float32 (created by layer 'keras_layer')>"]},"metadata":{},"execution_count":57}]},{"cell_type":"code","source":["#import random as rn\n","'''\n","def aucroc(y_true, y_pred):\n","    return tf.py_function(roc_auc_score, (y_true, y_pred), tf.double)\n","'''"],"metadata":{"id":"lFKk_oJDw-tx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# this function not working\n","\n","def build_classifier_model():\n","  tf.keras.backend.clear_session()\n","  np.random.seed(0)\n","  rn.seed(0)\n","\n","  #text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n","  #preprocessing_layer = hub.KerasLayer(tfhub_handle_preprocess, name='preprocessing')\n","  #encoder_inputs = preprocessing_layer(text_input)\n","  #encoder_inputs = []\n","  \n","  #this is input word. Sequence of words represented as integers\n","  max_seq_length = 55\n","  input_word_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32, name=\"input_word_ids\")\n","  input_mask = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32, name=\"input_mask\")\n","  segment_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32, name=\"segment_ids\")\n","\n","  tfhub_handle_encoder = \"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1\"\n","  encoder = hub.KerasLayer(tfhub_handle_encoder, trainable=False , name='BERT_encoder')\n","  outputs = encoder([ input_word_ids , input_mask , segment_ids ])\n","\n","  net1 = outputs['pooled_output']\n","  net2 = tf.keras.layers.Dropout(0.1)(net1)\n","  #net = tf.keras.layers.Dense(1, activation=None, name='classifier')(net)\n","  #dense4 = Dense(units=32,activation='relu',kernel_initializer=tf.keras.initializers.glorot_normal(seed=32),name='dense4')(dropout_1)\n","  #dropout_2 = Dropout(0.1)(dense4)\n","\n","  out1 = Dense(units=1,activation='sigmoid',kernel_initializer=tf.keras.initializers.glorot_normal(seed=34),name='output')(net2)\n","\n","  temp_model = tf.keras.Model( [input_word_ids, input_mask, segment_ids] , out1 )\n","  #temp_model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.01),loss='categorical_crossentropy',metrics=['accuracy',aucroc])\n","  \n","  return temp_model\n","\n","#temp_model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.01),loss='categorical_crossentropy',metrics=['accuracy',aucroc])\n"],"metadata":{"id":"00eFbueOtxuJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# this function works\n","def build_bert_model_2( ):\n","    tf.keras.backend.clear_session()\n","    np.random.seed(0)\n","    rn.seed(0)\n","\n","    max_len=55\n","    input_word_ids = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n","    input_mask = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"input_mask\")\n","    segment_ids = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"segment_ids\")\n","\n","    bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1\", trainable=False ,name='BERT_encoder')\n","    pooled_output , sequence_output = bert_layer([input_word_ids, input_mask, segment_ids])\n","    print( pooled_output )\n","    \n","    #clf_output = None #sequence_output[:, 0, :]\n","    \n","    net = tf.keras.layers.Dense(64, activation='relu')( pooled_output )\n","    net = tf.keras.layers.Dropout(0.1)(net)\n","    #net = tf.keras.layers.Dense(16, activation='relu')(net)\n","    #net = tf.keras.layers.Dropout(0.1)(net)\n","    out = tf.keras.layers.Dense(1, activation='sigmoid')(net)\n","    \n","    model2 = tf.keras.models.Model(inputs=[input_word_ids, input_mask, segment_ids], outputs=out)\n","\n","    model2.compile(tf.keras.optimizers.Adam(learning_rate=1e-5), loss='binary_crossentropy', metrics=['accuracy', aucroc ])\n","    \n","    return model2\n"],"metadata":{"id":"vXqIbwy60o3Q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["bert_model_1 = build_bert_model_2()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w-k6URtVwkLm","outputId":"482b0486-5605-47e3-a7a7-dd26f506e978"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["KerasTensor(type_spec=TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), name='BERT_encoder/StatefulPartitionedCall:0', description=\"created by layer 'BERT_encoder'\")\n"]}]},{"cell_type":"code","source":["bert_model_1.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mq7Av60z2VZV","outputId":"5e17a82f-f51b-436b-ab30-5b763c1ca28c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_word_ids (InputLayer)    [(None, 55)]         0           []                               \n","                                                                                                  \n"," input_mask (InputLayer)        [(None, 55)]         0           []                               \n","                                                                                                  \n"," segment_ids (InputLayer)       [(None, 55)]         0           []                               \n","                                                                                                  \n"," BERT_encoder (KerasLayer)      [(None, 768),        109482241   ['input_word_ids[0][0]',         \n","                                 (None, 55, 768)]                 'input_mask[0][0]',             \n","                                                                  'segment_ids[0][0]']            \n","                                                                                                  \n"," dense (Dense)                  (None, 64)           49216       ['BERT_encoder[0][0]']           \n","                                                                                                  \n"," dropout (Dropout)              (None, 64)           0           ['dense[0][0]']                  \n","                                                                                                  \n"," dense_1 (Dense)                (None, 1)            65          ['dropout[0][0]']                \n","                                                                                                  \n","==================================================================================================\n","Total params: 109,531,522\n","Trainable params: 49,281\n","Non-trainable params: 109,482,241\n","__________________________________________________________________________________________________\n"]}]},{"cell_type":"code","source":["\n","bert_model_1.fit(x = [X_train_tokens, X_train_mask, X_train_segment ] , y=y_train , batch_size=256 , epochs=1 ) #, \\\n","#          validation_data=([X_test_tokens, X_test_mask, X_test_segment] , y_test ) , validation_batch_size=256  )\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d1VpI21m6zD8","outputId":"9d962f22-df8f-4efd-cdd7-e9443d7981f0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["313/313 [==============================] - 305s 926ms/step - loss: 0.4292 - accuracy: 0.8467 - aucroc: 0.5776\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f612cf00750>"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["#bert_model_1.fit()\n","\n","bert_model_1.fit(x = [X_train_tokens, X_train_mask, X_train_segment] , y=y_train , batch_size=256 , epochs=10 , \\\n","          validation_data=([X_test_tokens, X_test_mask, X_test_segment] , y_test ) , validation_batch_size=256  )\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":432},"id":"TGOtN0hJ28Ye","outputId":"947f327a-ce36-41cd-bc45-7f90402b87af"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","313/313 [==============================] - 388s 1s/step - loss: 0.0000e+00 - accuracy: 0.1355 - val_loss: 0.0000e+00 - val_accuracy: 0.1300\n","Epoch 2/10\n"," 17/313 [>.............................] - ETA: 4:42 - loss: 0.0000e+00 - accuracy: 0.1252"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-26-85e4dba854cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#bert_model_1.fit()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mbert_model_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mX_train_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train_segment\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m \u001b[0;34m,\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_test_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test_segment\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mvalidation_batch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m  \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"IxdIlOIBlm7j"},"source":["# get the train output, BERT model will give one output so save in\n","# X_train_pooled_output\n","#X_train_pooled_output=bert_model.predict([X_train_tokens, X_train_mask, X_train_segment])\n","\n","#X_train_pooled_output=bert_model([X_train_tokens, X_train_mask, X_train_segment])"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# get the train output, BERT model will give one output so save in\n","# X_train_pooled_output\n","X_train_pooled_output=bert_model.predict([X_train_tokens, X_train_mask, X_train_segment])\n"],"metadata":{"id":"Vbve-yFBVSD9"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7Xsa7FTC8eCL","outputId":"0b62d5a2-8eae-4869-dbed-a3f61175dfe9","colab":{"base_uri":"https://localhost:8080/"}},"source":["X_train_pooled_output.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(80000, 768)"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"yZT11BCol4gL"},"source":["# get the test output, BERT model will give one output so save in\n","# X_test_pooled_output\n","X_test_pooled_output = bert_model.predict([X_test_tokens, X_test_mask, X_test_segment])\n","\n","#X_test_pooled_output = bert_model([X_test_tokens, X_test_mask, X_test_segment])\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"C4nyVc7N8qWg","outputId":"148e2087-92b9-4f43-acc9-13027b3e7803","colab":{"base_uri":"https://localhost:8080/"}},"source":["X_test_pooled_output.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(20000, 768)"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"DL6JVojfqVB8"},"source":["##save all your results to disk so that, no need to run all again. \n","#pickle.dump((X_train_pooled_output, X_test_pooled_output),open( data_path + 'final_output_1.pkl','wb'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oSQcBdROqVB9"},"source":["#X_train_pooled_output, X_test_pooled_output= pickle.load(open('final_output_1.pkl', 'rb'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qHnOznVnTVwD"},"source":["#X_train_pooled_output, X_test_pooled_output= pickle.load(open( data_path + 'final_output_1.pkl', 'rb'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5HBPqmFjTcMJ","outputId":"bc9b93d5-bb43-4835-914d-7e71c061cad1","colab":{"base_uri":"https://localhost:8080/"}},"source":["X_train_pooled_output.shape , X_test_pooled_output.shape\n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((80000, 768), (20000, 768))"]},"metadata":{},"execution_count":15}]},{"cell_type":"markdown","metadata":{"id":"ulEXFE7aqVCA"},"source":["<font size=4>Grader function 6 </font>"]},{"cell_type":"code","metadata":{"id":"oHCsW0IvqVCB","outputId":"95e349df-bc3c-4f53-cd41-15b573d78429","colab":{"base_uri":"https://localhost:8080/"}},"source":["#now we have X_train_pooled_output, y_train\n","#X_test_pooled_ouput, y_test\n","\n","#please use this grader to evaluate\n","def greader_output():\n","    assert(X_train_pooled_output.shape[1]==768)\n","    assert(len(y_train)==len(X_train_pooled_output))\n","    assert(X_test_pooled_output.shape[1]==768)\n","    assert(len(y_test)==len(X_test_pooled_output))\n","    assert(len(y_train.shape)==1)\n","    assert(len(X_train_pooled_output.shape)==2)\n","    assert(len(y_test.shape)==1)\n","    assert(len(X_test_pooled_output.shape)==2)\n","    return True\n","greader_output()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":16}]},{"cell_type":"markdown","metadata":{"id":"oYwS1QbAqVCD"},"source":["<pre><font size=6>Part-5: Training a NN with 768 features</font>\n","\n","Create a NN and train the NN. \n","1.<b> You have to use AUC as metric.</b> \n","2. You can use any architecture you want. \n","3. You have to use tensorboard to log all your metrics and Losses. You have to send those logs. \n","4. Print the loss and metric at every epoch. \n","5. You have to submit without overfitting and underfitting. \n","</pre>"]},{"cell_type":"code","metadata":{"id":"od8PQlYRqVCE"},"source":["##imports\n","#from tensorflow.keras.layers import Input, Dense, Activation, Dropout,MaxPooling1D,Conv1D\n","#from tensorflow.keras.models import Model\n","#import datetime\n","#from sklearn.metrics import roc_auc_score\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Dw337PyFdQFY"},"source":["\n","def aucroc(y_true, y_pred):\n","    return tf.py_function(roc_auc_score, (y_true, y_pred), tf.double)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DSnmX3WnqVCG","outputId":"9a90b4ff-b696-4d08-f3b0-70592db933a9","colab":{"base_uri":"https://localhost:8080/"}},"source":["##create an NN and \n","\n","tf.keras.backend.clear_session()\n","## Set the random seed values to regenerate the model.\n","np.random.seed(0)\n","rn.seed(0)\n","\n","#Input layer\n","input_layer1 = Input(shape=( 768 , ),name='Input_Layer')\n","#conv1d1 = Conv1D(filters=64, kernel_size=1 ,strides=(1), activation='relu')(input_layer1)\n","#max_pool_1 = MaxPooling1D(  pool_size=2, strides= 1 , padding=\"valid\", data_format=\"channels_last\", name=\"MaxPool1\" )(input_layer1)\n","#dropout_1 = Dropout(0.2)(max_pool_1)\n","dense1 = Dense(units=64,activation='relu',kernel_initializer=tf.keras.initializers.glorot_normal(seed=29),name='dense1')(input_layer1)\n","dropout_2 = Dropout(0.1)(dense1)\n","#dense2 = Dense(units=256,activation='relu',kernel_initializer=tf.keras.initializers.glorot_normal(seed=30),name='dense2')(dense1)\n","#dropout_2 = Dropout(0.5)(dense1)\n","#dense3 = Dense(units=128,activation='relu',kernel_initializer=tf.keras.initializers.glorot_normal(seed=31),name='dense3')(dense2)\n","#dropout_1 = Dropout(0.1)(dense3)\n","\n","#dense4 = Dense(units=32,activation='relu',kernel_initializer=tf.keras.initializers.glorot_normal(seed=32),name='dense4')(dropout_1)\n","#dropout_2 = Dropout(0.1)(dense4)\n","\n","#dense5 = Dense(units=16,activation='relu',kernel_initializer=tf.keras.initializers.glorot_normal(seed=33),name='dense5')(dropout_2)\n","#GlobalMaxPooling1D()\n","#dropout_3 = Dropout(0.1)(dense5)\n","\n","out1 = Dense(units=1,activation='sigmoid',kernel_initializer=tf.keras.initializers.glorot_normal(seed=34),name='output')(dropout_2)\n","\n","'''\n","model = Sequential()\n","model.add(Embedding(vocab_size, vec_size, input_length=max_length))\n","model.add(Conv1D(64, 8, activation = 'relu'))\n","model.add(MaxPooling1D(2))\n","model.add(Dropout(0.2))\n","model.add(Dense(32, activation='relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(16, activation='relu'))\n","model.add(GlobalMaxPooling1D())\n","model.add(Dense(1, activation='sigmoid'))\n","'''\n","model_nn = Model(inputs= input_layer1 , outputs= out1 )\n","\n","#model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.01),loss='categorical_crossentropy',metrics=['accuracy',aucroc])\n","model_nn.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),loss='binary_crossentropy',metrics=['accuracy', aucroc ])\n","\n","model_nn.summary()\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," Input_Layer (InputLayer)    [(None, 768)]             0         \n","                                                                 \n"," dense1 (Dense)              (None, 64)                49216     \n","                                                                 \n"," dropout (Dropout)           (None, 64)                0         \n","                                                                 \n"," output (Dense)              (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 49,281\n","Trainable params: 49,281\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["model_nn.fit(x = X_train_pooled_output , y=y_train , batch_size=256 , epochs=10 , \\\n","          validation_data=(X_test_pooled_output , y_test ) , validation_batch_size=256  )\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zYvd1Xh3ZHFm","outputId":"03c167fc-9db8-4d83-abea-e41e62c41e43"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","313/313 [==============================] - 3s 10ms/step - loss: 0.2238 - accuracy: 0.9068 - aucroc: 0.9269 - val_loss: 0.2515 - val_accuracy: 0.9007 - val_aucroc: 0.9310\n","Epoch 2/10\n","313/313 [==============================] - 3s 9ms/step - loss: 0.2135 - accuracy: 0.9122 - aucroc: 0.9324 - val_loss: 0.2016 - val_accuracy: 0.9172 - val_aucroc: 0.9354\n","Epoch 3/10\n","313/313 [==============================] - 2s 6ms/step - loss: 0.2112 - accuracy: 0.9134 - aucroc: 0.9361 - val_loss: 0.2263 - val_accuracy: 0.9020 - val_aucroc: 0.9370\n","Epoch 4/10\n","313/313 [==============================] - 2s 6ms/step - loss: 0.2106 - accuracy: 0.9141 - aucroc: 0.9367 - val_loss: 0.2086 - val_accuracy: 0.9146 - val_aucroc: 0.9412\n","Epoch 5/10\n","313/313 [==============================] - 2s 6ms/step - loss: 0.2028 - accuracy: 0.9172 - aucroc: 0.9401 - val_loss: 0.2634 - val_accuracy: 0.8938 - val_aucroc: 0.9387\n","Epoch 6/10\n","313/313 [==============================] - 2s 7ms/step - loss: 0.2040 - accuracy: 0.9166 - aucroc: 0.9398 - val_loss: 0.1936 - val_accuracy: 0.9210 - val_aucroc: 0.9422\n","Epoch 7/10\n","313/313 [==============================] - 2s 6ms/step - loss: 0.2056 - accuracy: 0.9147 - aucroc: 0.9381 - val_loss: 0.1920 - val_accuracy: 0.9219 - val_aucroc: 0.9438\n","Epoch 8/10\n","313/313 [==============================] - 2s 6ms/step - loss: 0.2002 - accuracy: 0.9144 - aucroc: 0.9410 - val_loss: 0.1979 - val_accuracy: 0.9238 - val_aucroc: 0.9444\n","Epoch 9/10\n","313/313 [==============================] - 2s 6ms/step - loss: 0.1961 - accuracy: 0.9161 - aucroc: 0.9433 - val_loss: 0.1953 - val_accuracy: 0.9115 - val_aucroc: 0.9446\n","Epoch 10/10\n","313/313 [==============================] - 2s 6ms/step - loss: 0.2088 - accuracy: 0.9122 - aucroc: 0.9398 - val_loss: 0.1959 - val_accuracy: 0.9206 - val_aucroc: 0.9426\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f6a83f060d0>"]},"metadata":{},"execution_count":57}]},{"cell_type":"code","source":["model_nn.evaluate( X_test_pooled_output , y_test , batch_size=256)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l7bvf7_sZpFB","outputId":"79acb294-87c9-4edc-f888-25034aeb2a9a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["79/79 [==============================] - 0s 4ms/step - loss: 0.1959 - accuracy: 0.9206 - aucroc: 0.9426\n"]},{"output_type":"execute_result","data":{"text/plain":["[0.19594620168209076, 0.9205999970436096, 0.9426466822624207]"]},"metadata":{},"execution_count":58}]},{"cell_type":"code","metadata":{"id":"LvNJegs4X_WI","outputId":"b27c37e2-1586-4618-8ddc-01bf181451bd","colab":{"base_uri":"https://localhost:8080/"}},"source":["#log_dir= data_path + \"logs/fit/\" + datetime.datetime.now().strftime(\"%d%m%Y-%H%M%S\")\n","#tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir,histogram_freq=0, write_graph=True,write_grads=True)\n","\n","# old Model\n","\n","model.fit(x = X_train_pooled_output , y=y_train , batch_size=256 , epochs=10 , \\\n","          validation_data=(X_test_pooled_output , y_test ) , validation_batch_size=256  )\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:`write_grads` will be ignored in TensorFlow 2.0 for the `TensorBoard` Callback.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:`write_grads` will be ignored in TensorFlow 2.0 for the `TensorBoard` Callback.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/5\n","  2/800 [..............................] - ETA: 29s - loss: 1.0252e-07 - accuracy: 0.1400 - aucroc: 0.6461WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0076s vs `on_train_batch_end` time: 0.0664s). Check your callbacks.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0076s vs `on_train_batch_end` time: 0.0664s). Check your callbacks.\n"],"name":"stderr"},{"output_type":"stream","text":["800/800 [==============================] - 4s 6ms/step - loss: 1.0370e-07 - accuracy: 0.1301 - aucroc: 0.5241 - val_loss: 1.0370e-07 - val_accuracy: 0.1301 - val_aucroc: 0.5229\n","Epoch 2/5\n","800/800 [==============================] - 5s 6ms/step - loss: 1.0370e-07 - accuracy: 0.1301 - aucroc: 0.5236 - val_loss: 1.0370e-07 - val_accuracy: 0.1301 - val_aucroc: 0.5229\n","Epoch 3/5\n","800/800 [==============================] - 4s 5ms/step - loss: 1.0370e-07 - accuracy: 0.1301 - aucroc: 0.5240 - val_loss: 1.0370e-07 - val_accuracy: 0.1301 - val_aucroc: 0.5229\n","Epoch 4/5\n","800/800 [==============================] - 4s 5ms/step - loss: 1.0370e-07 - accuracy: 0.1301 - aucroc: 0.5235 - val_loss: 1.0370e-07 - val_accuracy: 0.1301 - val_aucroc: 0.5229\n","Epoch 5/5\n","800/800 [==============================] - 4s 6ms/step - loss: 1.0370e-07 - accuracy: 0.1301 - aucroc: 0.5244 - val_loss: 1.0370e-07 - val_accuracy: 0.1301 - val_aucroc: 0.5229\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7fc932e51748>"]},"metadata":{"tags":[]},"execution_count":96}]},{"cell_type":"code","metadata":{"id":"c76EjPxGbLPn"},"source":["log_dir= data_path + \"logs/fit/\" + datetime.datetime.now().strftime(\"%d%m%Y-%H%M%S\")\n","log_dir"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kcILeYZI9pxm"},"source":["<Pre><font size=6>Part-6: Creating a Data pipeline for BERT Model</font> \n","\n","1. load data\n","2. Read the csv file\n","3. Remove all the html tags\n","4. Now do tokenization [Part 3 as mentioned above]\n","    * Create tokens,mask array and segment array\n","5. Get Embeddings from BERT Model [Part 4 as mentioned above] , let it be X_test\n","   * Print the shape of output(X_test.shape).You should get (352,768)\n","6. Predit the output of X_test with the Neural network model which we trained earlier.\n","7. Print the occurences of class labels in the predicted output\n","\n","</pre>"]},{"cell_type":"code","metadata":{"id":"iiBeOnna9yDH","outputId":"75b69b03-8801-44bd-e252-a8027d6555d2","colab":{"base_uri":"https://localhost:8080/"}},"source":["test_data = pd.read_csv( '/content/26_NLP_Transfer/' +'test.csv')\n","#data_path\n","test_data.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(352, 1)"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"IeE6kgGZldnD","outputId":"b0c6b1ac-e7e5-4716-f4c1-4139146b0107","colab":{"base_uri":"https://localhost:8080/","height":206}},"source":["test_data.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                Text\n","0  Just opened Greenies Joint Care (individually ...\n","1  This product rocks :) My mom was very happy w/...\n","2  The product was fine, but the cost of shipping...\n","3  I love this soup. It's great as part of a meal...\n","4  Getting ready to order again. These are great ..."],"text/html":["\n","  <div id=\"df-960fc036-e58e-4df7-be9c-e2141e55194e\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Just opened Greenies Joint Care (individually ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>This product rocks :) My mom was very happy w/...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>The product was fine, but the cost of shipping...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>I love this soup. It's great as part of a meal...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Getting ready to order again. These are great ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-960fc036-e58e-4df7-be9c-e2141e55194e')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-960fc036-e58e-4df7-be9c-e2141e55194e button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-960fc036-e58e-4df7-be9c-e2141e55194e');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":23}]},{"cell_type":"code","metadata":{"id":"TNiKjAYakTYM"},"source":["test_data['Text'] = test_data['Text'].apply( text_preprocess )\n","\n","X_te_1 = test_data['Text']\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9R0OonYPnS9u","outputId":"b41f131c-c297-402d-9621-1a5dd1a0c13d","colab":{"base_uri":"https://localhost:8080/"}},"source":["test_data.shape , X_te_1.shape #, X_te_1[0].shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((352, 1), (352,))"]},"metadata":{},"execution_count":32}]},{"cell_type":"code","source":["X_te_1[0:10].values"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u2AGOtcraV8x","outputId":"b8d86be1-249d-49fa-fa5b-4c8f16e4d3a9"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array(['just opened greenies joint care  individually sealed  in december 2011 and found small worm crawling all over it   next one looked fine  but really supposed to trust these now ',\n","       'this product rocks    my mom was very happy w the product it was excatly as described we loved seeing all the candy and eating it all   ',\n","       'the product was fine  but the cost of shipping was more than the cost of the tea   wo not make that mistake again ',\n","       'i love this soup  it is great as part of a meal or as a nutritious and satisifying low in calorie snack  for a light lunch  i stir in some shreeded cheese ',\n","       'getting ready to order again  these are great because they compost very quickly  but  some of the bags have tears in the bottom  so remember to always carry extra so you have emergency  back up  bags   a bit costly but  again  better for the environment ',\n","       'these were delicious  but not wrapped as well as i think they should be   they kind of melted out of their wrapping ',\n","       'i will never again even consider a dog food with corn  wheat or soy in it  grain has no place in a dog is diet ',\n","       'if you need something to take with you to keep your blood sugar up  this high fiber  high protein snack is just the thing ',\n","       'my husband puts this on everything  it is very expensive to buy in the grocery store and it comes in a small bottle  this bottle is huge  it is a great buy  there is enough to bottle and give away to others ',\n","       'this is a movie the whole family can watch together   it has great comedy  a little sacary and lots of laughs '],\n","      dtype=object)"]},"metadata":{},"execution_count":33}]},{"cell_type":"code","metadata":{"id":"8mmvDT2ZmqWT"},"source":["X_te_tokens, X_te_mask, X_te_segment = [] , [] , []\n","\n","for i in range( X_te_1.shape[0]):\n","    \n","    tokens = tokenizer.tokenize( ( X_te_1[i] ) )\n","    tokens = tokens[ 0 : ( max_seq_length - 2 )]\n","    tokens = ['[CLS]',*tokens,'[SEP]']\n","    \n","    X_te_tokens.append( np.array( tokenizer.convert_tokens_to_ids(tokens) +  [0]*( max_seq_length - len(tokens))  ) )\n","    \n","    X_te_mask.append( np.array([1]*len(tokens) + [0]*( max_seq_length - len(tokens))))\n","    \n","    X_te_segment.append(np.array( [0]*( max_seq_length )))\n","\n","X_te_tokens = np.array( X_te_tokens )\n","X_te_mask = np.array( X_te_mask )\n","X_te_segment = np.array( X_te_segment )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BBJyburApN70","outputId":"42a6f256-b1a1-4f79-f47d-2969906c7e13","colab":{"base_uri":"https://localhost:8080/"}},"source":["X_te_tokens.shape , X_te_mask.shape , X_te_segment.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((352, 55), (352, 55), (352, 55))"]},"metadata":{},"execution_count":39}]},{"cell_type":"code","metadata":{"id":"ZSQgHqWPpqQx"},"source":["X_test_pooled_op = bert_model.predict([ X_te_tokens , X_te_mask , X_te_segment ]) "],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_test_pooled_op.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QZ2WW-dNa2OI","outputId":"828f15e5-9b7a-4d9e-cc24-f4e7421fb1eb"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(352, 768)"]},"metadata":{},"execution_count":41}]},{"cell_type":"code","metadata":{"id":"2vn-VhPfqNgz"},"source":["predicted_y = model_nn.predict( X_test_pooled_op )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VqNPB4e_qqkO","outputId":"9002f279-895d-4936-ed69-a75e1c3f6d2e","colab":{"base_uri":"https://localhost:8080/"}},"source":["print(predicted_y.shape)\n","predicted_y"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(352, 1)\n"]},{"output_type":"execute_result","data":{"text/plain":["array([[0.64654607],\n","       [0.99570906],\n","       [0.36893794],\n","       [0.9600499 ],\n","       [0.9803402 ],\n","       [0.78969705],\n","       [0.8268261 ],\n","       [0.994932  ],\n","       [0.994044  ],\n","       [0.9935108 ],\n","       [0.9024153 ],\n","       [0.9556741 ],\n","       [0.554749  ],\n","       [0.9157876 ],\n","       [0.92947936],\n","       [0.43624252],\n","       [0.99680823],\n","       [0.9114974 ],\n","       [0.87107605],\n","       [0.955121  ],\n","       [0.724998  ],\n","       [0.97300977],\n","       [0.7591065 ],\n","       [0.92691225],\n","       [0.95712703],\n","       [0.9699526 ],\n","       [0.9803175 ],\n","       [0.9193082 ],\n","       [0.9291376 ],\n","       [0.9898239 ],\n","       [0.53297853],\n","       [0.92045456],\n","       [0.95925915],\n","       [0.98949885],\n","       [0.9711936 ],\n","       [0.9971016 ],\n","       [0.51176274],\n","       [0.9905184 ],\n","       [0.99745697],\n","       [0.99220204],\n","       [0.32184538],\n","       [0.99750465],\n","       [0.9708457 ],\n","       [0.9354391 ],\n","       [0.31295896],\n","       [0.7705564 ],\n","       [0.9873089 ],\n","       [0.8006434 ],\n","       [0.9881583 ],\n","       [0.91992414],\n","       [0.9944841 ],\n","       [0.87712806],\n","       [0.95008916],\n","       [0.5567309 ],\n","       [0.4640965 ],\n","       [0.97934043],\n","       [0.97197354],\n","       [0.9102908 ],\n","       [0.97853523],\n","       [0.99819463],\n","       [0.9636912 ],\n","       [0.9992719 ],\n","       [0.97869956],\n","       [0.78891957],\n","       [0.9467068 ],\n","       [0.99576664],\n","       [0.9992787 ],\n","       [0.9953734 ],\n","       [0.98683864],\n","       [0.8994317 ],\n","       [0.9226927 ],\n","       [0.9945762 ],\n","       [0.8135558 ],\n","       [0.9565375 ],\n","       [0.98217154],\n","       [0.9473881 ],\n","       [0.9957606 ],\n","       [0.91767865],\n","       [0.99391925],\n","       [0.9927301 ],\n","       [0.98844004],\n","       [0.26296842],\n","       [0.8094788 ],\n","       [0.76420015],\n","       [0.38664624],\n","       [0.39077902],\n","       [0.59301937],\n","       [0.9982755 ],\n","       [0.9259952 ],\n","       [0.9400888 ],\n","       [0.9200893 ],\n","       [0.9647016 ],\n","       [0.915926  ],\n","       [0.9955481 ],\n","       [0.992504  ],\n","       [0.99465275],\n","       [0.41424674],\n","       [0.92407596],\n","       [0.7959269 ],\n","       [0.99791735],\n","       [0.99748343],\n","       [0.9929917 ],\n","       [0.98503   ],\n","       [0.87393826],\n","       [0.9966271 ],\n","       [0.9528865 ],\n","       [0.98693186],\n","       [0.9603601 ],\n","       [0.9169625 ],\n","       [0.9431259 ],\n","       [0.9539881 ],\n","       [0.99597067],\n","       [0.99945134],\n","       [0.99482036],\n","       [0.9870663 ],\n","       [0.98514754],\n","       [0.9590497 ],\n","       [0.97660905],\n","       [0.979146  ],\n","       [0.97460914],\n","       [0.999161  ],\n","       [0.97473323],\n","       [0.34654197],\n","       [0.95693535],\n","       [0.95626837],\n","       [0.99841106],\n","       [0.9859022 ],\n","       [0.98392475],\n","       [0.6770564 ],\n","       [0.96095777],\n","       [0.75699556],\n","       [0.7835004 ],\n","       [0.99012893],\n","       [0.9391032 ],\n","       [0.9867937 ],\n","       [0.9185352 ],\n","       [0.9510572 ],\n","       [0.5146777 ],\n","       [0.99929976],\n","       [0.8951147 ],\n","       [0.9905488 ],\n","       [0.44943506],\n","       [0.75045645],\n","       [0.9611506 ],\n","       [0.99911803],\n","       [0.9895544 ],\n","       [0.9955592 ],\n","       [0.8733895 ],\n","       [0.93482625],\n","       [0.7895069 ],\n","       [0.9915719 ],\n","       [0.38052368],\n","       [0.9950488 ],\n","       [0.9883484 ],\n","       [0.9211182 ],\n","       [0.40088207],\n","       [0.99272233],\n","       [0.99057126],\n","       [0.52230763],\n","       [0.62624866],\n","       [0.99264866],\n","       [0.9111903 ],\n","       [0.9387112 ],\n","       [0.9835638 ],\n","       [0.99517053],\n","       [0.9830815 ],\n","       [0.967506  ],\n","       [0.85449725],\n","       [0.98405564],\n","       [0.9992386 ],\n","       [0.9321962 ],\n","       [0.66136307],\n","       [0.43749344],\n","       [0.8791683 ],\n","       [0.47015885],\n","       [0.99386805],\n","       [0.9645484 ],\n","       [0.7417378 ],\n","       [0.9595395 ],\n","       [0.9843716 ],\n","       [0.5879304 ],\n","       [0.96535605],\n","       [0.9974095 ],\n","       [0.9922206 ],\n","       [0.9894252 ],\n","       [0.7728692 ],\n","       [0.7538862 ],\n","       [0.9192078 ],\n","       [0.9952813 ],\n","       [0.35360968],\n","       [0.9814549 ],\n","       [0.85984534],\n","       [0.97498655],\n","       [0.9949764 ],\n","       [0.870201  ],\n","       [0.506082  ],\n","       [0.9431206 ],\n","       [0.971473  ],\n","       [0.9562627 ],\n","       [0.98923093],\n","       [0.99617046],\n","       [0.9990445 ],\n","       [0.869381  ],\n","       [0.9375955 ],\n","       [0.99883765],\n","       [0.9966588 ],\n","       [0.99602145],\n","       [0.7968875 ],\n","       [0.9664442 ],\n","       [0.9731386 ],\n","       [0.9760809 ],\n","       [0.99281365],\n","       [0.8161506 ],\n","       [0.99736494],\n","       [0.87549466],\n","       [0.98500836],\n","       [0.9939569 ],\n","       [0.98789525],\n","       [0.99703276],\n","       [0.9873562 ],\n","       [0.9985348 ],\n","       [0.51915467],\n","       [0.9756326 ],\n","       [0.9984907 ],\n","       [0.9977608 ],\n","       [0.706839  ],\n","       [0.97473633],\n","       [0.76046336],\n","       [0.9224574 ],\n","       [0.9936231 ],\n","       [0.8056553 ],\n","       [0.99458826],\n","       [0.30176064],\n","       [0.99841845],\n","       [0.9934408 ],\n","       [0.39113462],\n","       [0.9570311 ],\n","       [0.98585606],\n","       [0.9850441 ],\n","       [0.905451  ],\n","       [0.8437651 ],\n","       [0.98816866],\n","       [0.9837571 ],\n","       [0.996617  ],\n","       [0.61724114],\n","       [0.4643266 ],\n","       [0.9785217 ],\n","       [0.87656593],\n","       [0.93294775],\n","       [0.9748195 ],\n","       [0.6884286 ],\n","       [0.98676723],\n","       [0.9824851 ],\n","       [0.9926802 ],\n","       [0.99566084],\n","       [0.780664  ],\n","       [0.99717146],\n","       [0.40344882],\n","       [0.7334283 ],\n","       [0.93127185],\n","       [0.96815586],\n","       [0.32245696],\n","       [0.94831985],\n","       [0.9745954 ],\n","       [0.9832009 ],\n","       [0.9972778 ],\n","       [0.9900912 ],\n","       [0.99916685],\n","       [0.9923167 ],\n","       [0.9943509 ],\n","       [0.99730104],\n","       [0.3951161 ],\n","       [0.9981896 ],\n","       [0.99066216],\n","       [0.98952276],\n","       [0.9938222 ],\n","       [0.98273706],\n","       [0.96803755],\n","       [0.9500303 ],\n","       [0.958888  ],\n","       [0.9952247 ],\n","       [0.92447615],\n","       [0.953779  ],\n","       [0.9802185 ],\n","       [0.9933581 ],\n","       [0.9933115 ],\n","       [0.9928993 ],\n","       [0.84893167],\n","       [0.98584104],\n","       [0.99787486],\n","       [0.93606853],\n","       [0.58672345],\n","       [0.91611624],\n","       [0.980874  ],\n","       [0.9151378 ],\n","       [0.8613797 ],\n","       [0.9970186 ],\n","       [0.9163459 ],\n","       [0.9955491 ],\n","       [0.94677144],\n","       [0.97168005],\n","       [0.78595954],\n","       [0.7369642 ],\n","       [0.9958615 ],\n","       [0.94207543],\n","       [0.94474083],\n","       [0.9137136 ],\n","       [0.29558334],\n","       [0.9111119 ],\n","       [0.4562782 ],\n","       [0.67025334],\n","       [0.94113785],\n","       [0.99766695],\n","       [0.8536908 ],\n","       [0.9878566 ],\n","       [0.98274267],\n","       [0.79535335],\n","       [0.9627072 ],\n","       [0.9319194 ],\n","       [0.993193  ],\n","       [0.99708766],\n","       [0.79621994],\n","       [0.94935244],\n","       [0.40903756],\n","       [0.80148536],\n","       [0.9146041 ],\n","       [0.8011168 ],\n","       [0.5805141 ],\n","       [0.9954686 ],\n","       [0.8959879 ],\n","       [0.99449944],\n","       [0.6043776 ],\n","       [0.9740441 ],\n","       [0.9664927 ],\n","       [0.9735666 ],\n","       [0.99438465],\n","       [0.9310345 ],\n","       [0.9788311 ],\n","       [0.9934161 ],\n","       [0.97343665],\n","       [0.84944385],\n","       [0.84927493],\n","       [0.99464417],\n","       [0.9612053 ],\n","       [0.9950363 ],\n","       [0.97111726],\n","       [0.6761434 ],\n","       [0.9967704 ],\n","       [0.9770133 ],\n","       [0.8365279 ],\n","       [0.9918035 ],\n","       [0.9987375 ]], dtype=float32)"]},"metadata":{},"execution_count":43}]},{"cell_type":"code","source":["predicted_label = [1 if i > 0.5 else 0 for i in predicted_y ]\n","\n","labley , county = np.unique( np.array( predicted_label ),  return_counts=True)\n","\n","dict(zip(labley , county ))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j8SB9jMWcphY","outputId":"ef7fbbb6-7d57-40b0-e296-da1bbce86dba"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{0: 58, 1: 294}"]},"metadata":{},"execution_count":66}]}]}