{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"},"colab":{"provenance":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"AQDRNrY2NCXf"},"source":["<pre>\n","1. load the data\n","\n","2. Code the model to classify data like below image\n","\n","<img src='https://i.imgur.com/33ptOFy.png'>\n","\n","3. Write your own callback function, that has to print the micro F1 score and AUC score after each epoch.\n","\n","4. Save your model at every epoch if your validation accuracy is improved from previous epoch. \n","\n","5. you have to decay learning based on below conditions \n","        Cond1. If your validation accuracy at that epoch is less than previous epoch accuracy, you have to decrese the\n","               learning rate by 10%. \n","        Cond2. For every 3rd epoch, decay your learning rate by 5%.\n","        \n","6. If you are getting any NaN values(either weigths or loss) while training, you have to terminate your training. \n","\n","7. You have to stop the training if your validation accuracy is not increased in last 2 epochs.\n","\n","8. use cross entropy as loss function\n","\n","\n","</pre>"]},{"cell_type":"markdown","metadata":{"id":"w41Y3TFENCXk"},"source":["<pre>\n","<b>Model-1</b>\n","<pre>\n","1. Use tanh as an activation for every layer except output layer.\n","2. use SGD with momentum as optimizer.\n","3. use RandomUniform(0,1) as initilizer.\n","3. Analyze your output and training process. \n","</pre>\n","</pre>\n","<pre>\n","<b>Model-2</b>\n","<pre>\n","1. Use relu as an activation for every layer except output layer.\n","2. use SGD with momentum as optimizer.\n","3. use RandomUniform(0,1) as initilizer.\n","3. Analyze your output and training process. \n","</pre>\n","</pre>\n","<pre>\n","<b>Model-3</b>\n","<pre>\n","1. Use relu as an activation for every layer except output layer.\n","2. use SGD with momentum as optimizer.\n","3. use he_uniform() as initilizer.\n","3. Analyze your output and training process. \n","</pre>\n","</pre>\n","<pre>\n","\n","</pre>"]},{"cell_type":"code","metadata":{"id":"N9kxqIqGnVXd"},"source":["file_path_ = \"/content/\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KHJs59nnls9S"},"source":["import tensorflow as tf\n","import numpy as np\n","import pandas as pd\n","from tensorflow.keras.layers import Dense,Input,Activation\n","from tensorflow.keras.models import Model\n","import random as rn\n","\n","from sklearn.model_selection import train_test_split"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Nd-QMIqbmmmM","executionInfo":{"status":"ok","timestamp":1602137961485,"user_tz":-330,"elapsed":1266,"user":{"displayName":"chetan vanapariya","photoUrl":"","userId":"09687593949013731715"}},"outputId":"b550aa91-5f62-4888-b760-653b6fa0ba48","colab":{"base_uri":"https://localhost:8080/"}},"source":["tf.__version__  , tf.executing_eagerly()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["('2.3.0', True)"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"code","metadata":{"id":"QN1CXG_vnxQ9"},"source":["data_csv = pd.read_csv( file_path_ + \"data.csv\" , dtype={'label': 'int32' })"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"O1kby-UaoNgQ","executionInfo":{"status":"ok","timestamp":1656686121714,"user_tz":-330,"elapsed":644,"user":{"displayName":"chetan vanapariya","userId":"09687593949013731715"}},"outputId":"73ef2478-08d9-4c1a-ce97-ef25172f236b","colab":{"base_uri":"https://localhost:8080/","height":81}},"source":["data_csv.head(1)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["         f1        f2  label\n","0  0.450564  1.074305      0"],"text/html":["\n","  <div id=\"df-8a2b223e-9ab3-4934-bb9d-7d4d5d5f9145\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>f1</th>\n","      <th>f2</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.450564</td>\n","      <td>1.074305</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8a2b223e-9ab3-4934-bb9d-7d4d5d5f9145')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-8a2b223e-9ab3-4934-bb9d-7d4d5d5f9145 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-8a2b223e-9ab3-4934-bb9d-7d4d5d5f9145');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["data_csv.label.unique()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WwWGH4tMMM-J","executionInfo":{"status":"ok","timestamp":1656686277551,"user_tz":-330,"elapsed":839,"user":{"displayName":"chetan vanapariya","userId":"09687593949013731715"}},"outputId":"778714a2-1641-472e-d42b-df1fcf36588a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0, 1], dtype=int32)"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["data_csv.groupby(['label']).agg({'label' : ['count'] })"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":175},"id":"tdsGb4BwNVZR","executionInfo":{"status":"ok","timestamp":1656686586385,"user_tz":-330,"elapsed":509,"user":{"displayName":"chetan vanapariya","userId":"09687593949013731715"}},"outputId":"85012c47-0121-41b6-b98a-02976e033e83"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["       label\n","       count\n","label       \n","0      10000\n","1      10000"],"text/html":["\n","  <div id=\"df-e80e2840-9f50-4e78-a19f-fc9fd045f653\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead tr th {\n","        text-align: left;\n","    }\n","\n","    .dataframe thead tr:last-of-type th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr>\n","      <th></th>\n","      <th>label</th>\n","    </tr>\n","    <tr>\n","      <th></th>\n","      <th>count</th>\n","    </tr>\n","    <tr>\n","      <th>label</th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>10000</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>10000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e80e2840-9f50-4e78-a19f-fc9fd045f653')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-e80e2840-9f50-4e78-a19f-fc9fd045f653 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-e80e2840-9f50-4e78-a19f-fc9fd045f653');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":15}]},{"cell_type":"code","metadata":{"id":"kmKrE8RGr0KT"},"source":["# data_csv.drop( ['label'], axis=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_b78YP_br1kp","executionInfo":{"status":"ok","timestamp":1656686595186,"user_tz":-330,"elapsed":557,"user":{"displayName":"chetan vanapariya","userId":"09687593949013731715"}},"outputId":"f9d366e0-0fcb-4e66-d82f-874f114b2dd2","colab":{"base_uri":"https://localhost:8080/"}},"source":["# data_csv\n","data_y = data_csv['label'].values\n","data_x = data_csv.drop( ['label'], axis=1).values\n","data_x.shape , data_y.shape "],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((20000, 2), (20000,))"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"UQzp7vmlqjHD"},"source":["\n","#data_y = data_csv['label'].values\n","#data_x = data_csv.drop( ['label'], axis=1).values\n","# split the data into test and train by maintaining same distribution of output varaible 'data_y' [stratify=data_y]\n","X_train, X_test, Y_train, Y_test = train_test_split( data_x , data_y,stratify=data_y,test_size=0.20)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yovxYY3ptm8q","executionInfo":{"status":"ok","timestamp":1656686602969,"user_tz":-330,"elapsed":6,"user":{"displayName":"chetan vanapariya","userId":"09687593949013731715"}},"outputId":"945549d1-9727-42aa-8255-041a91ffa26d","colab":{"base_uri":"https://localhost:8080/"}},"source":["X_train.shape, Y_train.shape, X_test.shape, Y_test.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((16000, 2), (16000,), (4000, 2), (4000,))"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","metadata":{"id":"2xk_WPlwwc5B"},"source":["class LossHistory(tf.keras.callbacks.Callback):\n","    \n","    def on_train_begin(self, logs={}):\n","        ## on begin of training, we are creating a instance varible called history\n","        ## it is a dict with keys [loss, acc, val_loss, val_acc]\n","        self.history={'loss': [],'acc': [],'val_loss': [],'val_acc': []}\n","        \n","    def on_epoch_end(self, epoch, logs={}):\n","        ## on end of each epoch, we will get logs and update the self.history dict\n","        self.history['loss'].append(logs.get('loss'))\n","        self.history['acc'].append(logs.get('acc'))\n","        if logs.get('val_loss', -1) != -1:\n","            self.history['val_loss'].append(logs.get('val_loss'))\n","        if logs.get('val_acc', -1) != -1:\n","            self.history['val_acc'].append(logs.get('val_acc'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ToohB2QXGtXF"},"source":["class LearningRateCustom(tf.keras.callbacks.Callback):\n","      def __init__(self, schedule, verbose=0):\n","        super(LearningRateCustom, self).__init__()\n","        self.schedule = schedule\n","        self.verbose = verbose\n","\n","      def on_epoch_begin(self, epoch, logs=None):\n","        if not hasattr(self.model.optimizer, 'lr'):\n","          raise ValueError('Optimizer must have a \"lr\" attribute.')\n","        try:  # new API\n","          lr = float(K.get_value(self.model.optimizer.lr))\n","          lr = self.schedule(epoch, lr)\n","        except TypeError:  # Support for old API for backward compatibility\n","          lr = self.schedule(epoch)\n","        if not isinstance(lr, (ops.Tensor, float, np.float32, np.float64)):\n","          raise ValueError('The output of the \"schedule\" function '\n","                          'should be float.')\n","        if isinstance(lr, ops.Tensor) and not lr.dtype.is_floating:\n","          raise ValueError('The dtype of Tensor should be float')\n","        K.set_value(self.model.optimizer.lr, K.get_value(lr))\n","        if self.verbose > 0:\n","          print('\\nEpoch %05d: LearningRateScheduler reducing learning '\n","                'rate to %s.' % (epoch + 1, lr))\n","\n","      def on_epoch_end(self, epoch, logs=None):\n","        logs = logs or {}\n","        logs['lr'] = K.get_value(self.model.optimizer.lr)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3GnRAIB_6rRM"},"source":["#Custom Callback class\n","class LearningRate(tf.keras.callbacks.LearningRateScheduler):\n","    def __init__(self ,  schedule, verbose=0 ):\n","        print(\"__init__ called\")\n","        super(LearningRate, self ).__init__(  schedule, verbose )\n","        self.schedule = schedule\n","        self.verbose = verbose\n","\n","    def on_epoch_begin(self, epoch, logs=None):\n","        ## on begin of training, we are creating a instance varible called history\n","        ## it is a dict with keys [loss, acc, val_loss, val_acc]\n","        print(\"on LearningRate called\")\n","       # self.history_data={'loss': [],'acc': [],'val_loss': [],'val_acc': []}\n","        self.initial_learningrate = 0.1\n","        \n","    def on_epoch_end(self, epoch, logs=None):\n","        ## on end of each epoch, we will get logs and update the self.history dict\n","        print(\"on_epoch_end called\")\n","        print(\"logs : \" , logs )\n","        self.schedule(epoch)\n","        '''self.history_data['loss'].append(logs.get('loss'))\n","        self.history_data['acc'].append(logs.get('accuracy'))\n","        if logs.get('val_loss', -1) != -1:\n","            self.history_data['val_loss'].append(logs.get('val_loss'))\n","        if logs.get('val_accuracy', -1) != -1:\n","            self.history_data['val_acc'].append(logs.get('val_accuracy'))\n","\n","        # getting any NaN values(either weigths or loss) while training, it has to terminate your training.\n","        loss = logs.get('loss')\n","        if loss is not None:\n","            if np.isnan(loss) or np.isinf(loss):\n","                print(\"Invalid loss and terminated at epoch {}\".format(epoch))\n","                self.model.stop_training = True\n","        '''\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cMbFVaWElBju"},"source":["#Custom Callback class\n","class LossHistoryData(tf.keras.callbacks.Callback):\n","    def __init__(self):\n","        print(\"__init__ LossHistoryData\")\n","\n","    def on_train_begin(self, logs={}):\n","        ## on begin of training, we are creating a instance varible called history_data\n","        ## it is a dict with keys [loss, acc, val_loss, val_acc]\n","        #print(\"on_train_begin called\")\n","        self.history_data={'loss': [],'accuracy': [],'val_loss': [],'val_accuracy': []}\n","        \n","    def on_epoch_end(self, epoch, logs={}):\n","        ## on end of each epoch, we will get logs and update the self.history_data dict\n","        #print(\"on_epoch_end called\")\n","        print(\"epoch:\" , epoch)\n","        self.history_data['loss'].append(logs.get('loss'))\n","        self.history_data['accuracy'].append(logs.get('accuracy'))\n","        if logs.get('val_loss', -1) != -1:\n","            self.history_data['val_loss'].append(logs.get('val_loss'))\n","        if logs.get('val_accuracy', -1) != -1:\n","            self.history_data['val_accuracy'].append(logs.get('val_accuracy'))\n","\n","        if (epoch > 2):\n","          val_acc = self.history_data.get(\"val_accuracy\")\n","          if ( ( val_acc[epoch-1] < val_acc[epoch-2] ) and  ( val_acc[epoch-2] < val_acc[epoch-3]) ):\n","            #print(\"val_acc is not increased in last 2 epoch{}\".format(val_acc[epoch-3 : epoch]))\n","            print(\"val_acc is not increased in last 2 epoch\")\n","            self.model.stop_training = True\n","        # getting any NaN values(either weigths or loss) while training, it has to terminate your training.\n","        loss = logs.get('loss')\n","        if loss is not None:\n","            if np.isnan(loss) or np.isinf(loss):\n","                print(\"Invalid loss and terminated at epoch {}\".format(epoch))\n","                self.model.stop_training = True\n","\n","    #initial_learningrate=0.1\n","    def changeLearningRate4(self , epoch , lr ):\n","        #print( \"---> changeLearningRate : \" , epoch )\n","        #initial_learningrate=0.01\n","        val_loss = self.history_data.get(\"val_accuracy\")\n","        #print(lr , \"--->v_acc\" , val_loss)\n","        #lr = ( lr ) *(0.1)\n","        if ( epoch > 1):\n","          if ( (epoch % 3) == 0):\n","            lr = ( lr ) *(0.05)\n","          elif (val_loss[epoch-1] < val_loss[epoch-2]):\n","            lr = ( lr ) *(0.1)\n","        \n","        return lr"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZEqrKKD02rdp"},"source":["#initial_learningrate=0.1\n","def changeLearningRate(epoch , lr ):\n","        #print( \"---> changeLearningRate : \" , epoch )\n","        #initial_learningrate=0.01\n","        val_loss = history_own_data.history_data.get(\"val_accuracy\")\n","        #print(lr , \"--->v_acc\" , val_loss)\n","        #lr = ( lr ) *(0.1)\n","        if ( epoch > 1):\n","          if ( (epoch % 3) == 0):\n","            lr = ( lr ) *(0.05)\n","          elif (val_loss[epoch-1] < val_loss[epoch-2]):\n","            lr = ( lr ) *(0.1)\n","        \n","        return lr"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"W07Gsifn4J9L"},"source":["#changeLearningRate(None, None)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4If3dqdJu5Ge"},"source":["#Y_train = tf.keras.utils.to_categorical(Y_train, 10) \n","#Y_test = tf.keras.utils.to_categorical(Y_test, 10)\n","Y_train = tf.keras.utils.to_categorical(Y_train, 2) \n","Y_test = tf.keras.utils.to_categorical(Y_test, 2)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LptSWRRy2lt2"},"source":["#from tensorflow.keras.callbacks import LearningRateScheduler\n","from tensorflow.keras.callbacks import LearningRateScheduler\n","from sklearn.metrics import f1_score\n","from sklearn.metrics import roc_curve, auc , roc_auc_score\n","from tensorflow.keras.callbacks import ModelCheckpoint"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YN9CRQ_3zVsP"},"source":["class F1ScoreMetrics(tf.keras.callbacks.Callback):\n","    def __init__(self , validation ):   \n","        super(F1ScoreMetrics, self).__init__()\n","        self.validation_data = validation    \n","            \n","        print('validation shape', len(self.validation_data[0]))\n","        print(\"__init__F1ScoreMetrics\")\n","\n","    def on_train_begin(self, logs={}):        \n","        self.val_f1score = []\n","        self.auc_score = []\n","        #self.val_recalls = []\n","        #self.val_precisions = []\n","     \n","    def on_epoch_end(self, epoch, logs={}):\n","        #val_targ = self.validation[1]   \n","        #val_predict = (np.asarray(self.model.predict(self.validation[0]))).round()        \n","        val_x = self.validation_data[0]\n","        val_y = self.validation_data[1]\n","        val_predicted = (np.asarray(self.model.predict(val_x))).round() #(np.asarray()).round()\n","        #print(\"val_predicted : \" , val_predicted.shape )\n","        #print(\"val_y : \" , val_y.shape )\n","        val_f1 = f1_score(val_y, val_predicted ,  average='micro' )\n","        #val_recall = recall_score(val_targ, val_predict)         \n","        #val_precision = precision_score(val_targ, val_predict)\n","        #fpr,tpr,ths = roc_curve(np.mean(val_y, axis=1 ), np.mean( val_predicted , axis=1 ) )\n","        auc_sc = roc_auc_score( val_y, val_predicted , average='micro')\n","        #auc_sc = auc(fpr, tpr)\n","        \n","        self.val_f1score.append(round(val_f1, 6))\n","        self.auc_score.append( auc_sc )\n","        #self.val_recalls.append(round(val_recall, 6))\n","        #self.val_precisions.append(round(val_precision, 6))\n"," \n","        #print(f' — val_f1: {val_f1} — val_precision: {val_precision}, — val_recall: {val_recall}')\n","        print(f' — val_f1score: {val_f1} -- AUC : {auc_sc}' )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"R7tayZVO8cSA"},"source":["import os\n","\n","if (not os.path.isdir(\"/home/model_save\")):\n","    print(os.makedirs(\"/home/model_save\"))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"77t6dg_3lN6G","executionInfo":{"status":"ok","timestamp":1602156622705,"user_tz":-330,"elapsed":7361,"user":{"displayName":"chetan vanapariya","photoUrl":"","userId":"09687593949013731715"}},"outputId":"adbff847-f5c3-445f-c588-54d1520c08ac","colab":{"base_uri":"https://localhost:8080/"}},"source":["#to work with callback\n","\n","#Input layer\n","input_layer = Input(shape=(2,))\n","\n","#initializer = tf.keras.initializers.RandomUniform(minval=0., maxval=1.)\n","#Dense hidden layer\n","layer1 = Dense(50,activation='sigmoid',kernel_initializer=tf.keras.initializers.glorot_normal(seed=30))(input_layer)\n","\n","layer2 = Dense(40,activation='softmax',kernel_initializer=tf.keras.initializers.glorot_normal(seed=0))(layer1)\n","layer3 = Dense(30,activation='softmax',kernel_initializer=tf.keras.initializers.glorot_normal(seed=0))(layer2)\n","layer4 = Dense(20,activation='softmax',kernel_initializer=tf.keras.initializers.glorot_normal(seed=0))(layer3)\n","layer5 = Dense(10,activation='softmax',kernel_initializer=tf.keras.initializers.glorot_normal(seed=0))(layer4)\n","\n","#output layer\n","output = Dense(10,activation='softmax',kernel_initializer=tf.keras.initializers.glorot_normal(seed=0))(layer5)\n","#Creating a model\n","model = Model(inputs=input_layer,outputs=output)\n","\n","optimizer = tf.keras.optimizers.Adam(0.01)\n","#opt = tf.keras.optimizers.SGD(learning_rate=0.1, momentum=0.9)\n","#Callbacks\n","history_own_data = LossHistoryData()\n","#history_own_data = LossHistory()\n","lrschedule = tf.keras.callbacks.LearningRateScheduler( changeLearningRate, verbose=1)\n","#lrschedule = LearningRate(changeLearningRate , verbose=1)\n","f1score = F1ScoreMetrics( validation=(X_test,Y_test))\n","filepath=\"/home/model_save/weights-{epoch:02d}-{val_accuracy:.4f}.hdf5\"\n","checkpoint = ModelCheckpoint(filepath=filepath, monitor='val_loss',  verbose=1, save_best_only=True, mode='auto')\n","\n","call_back_list = [history_own_data , lrschedule , f1score , checkpoint ]\n","#optimizer = tf.keras.optimizers.Adam(0.01)\n","model.compile(optimizer=optimizer, loss='categorical_crossentropy',metrics=['accuracy'])\n","\n","model.fit(X_train,Y_train,epochs=3, validation_data=(X_test,Y_test), batch_size=16, callbacks= call_back_list )\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["__init__ LossHistoryData\n","validation shape 4000\n","__init__F1ScoreMetrics\n","\n","Epoch 00001: LearningRateScheduler reducing learning rate to 0.009999999776482582.\n","Epoch 1/3\n"," 987/1000 [============================>.] - ETA: 0s - loss: 0.7676 - accuracy: 0.4987epoch: 0\n"," — val_f1score: 0.5 -- AUC : 0.7222222222222221\n","\n","Epoch 00001: val_loss improved from inf to 0.69575, saving model to /home/model_save/weights-01-0.5000.hdf5\n","1000/1000 [==============================] - 2s 2ms/step - loss: 0.7666 - accuracy: 0.4991 - val_loss: 0.6958 - val_accuracy: 0.5000\n","\n","Epoch 00002: LearningRateScheduler reducing learning rate to 0.009999999776482582.\n","Epoch 2/3\n"," 993/1000 [============================>.] - ETA: 0s - loss: 0.6953 - accuracy: 0.5023epoch: 1\n"," — val_f1score: 0.5 -- AUC : 0.7222222222222221\n","\n","Epoch 00002: val_loss improved from 0.69575 to 0.69451, saving model to /home/model_save/weights-02-0.5000.hdf5\n","1000/1000 [==============================] - 2s 2ms/step - loss: 0.6954 - accuracy: 0.5019 - val_loss: 0.6945 - val_accuracy: 0.5000\n","\n","Epoch 00003: LearningRateScheduler reducing learning rate to 0.009999999776482582.\n","Epoch 3/3\n"," 994/1000 [============================>.] - ETA: 0s - loss: 0.6949 - accuracy: 0.4984epoch: 2\n"," — val_f1score: 0.5 -- AUC : 0.7222222222222221\n","\n","Epoch 00003: val_loss did not improve from 0.69451\n","1000/1000 [==============================] - 2s 2ms/step - loss: 0.6948 - accuracy: 0.4986 - val_loss: 0.7029 - val_accuracy: 0.5000\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f99ced607f0>"]},"metadata":{"tags":[]},"execution_count":111}]},{"cell_type":"code","metadata":{"id":"o_kz8ipO79lJ","executionInfo":{"status":"ok","timestamp":1602156693837,"user_tz":-330,"elapsed":2348,"user":{"displayName":"chetan vanapariya","photoUrl":"","userId":"09687593949013731715"}},"outputId":"db566531-9481-4945-b42e-22efb0ca8fed","colab":{"base_uri":"https://localhost:8080/"}},"source":["model.load_weights('/home/model_save/weights-02-0.5000.hdf5')\n","model.fit(X_train,Y_train)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["500/500 [==============================] - 1s 2ms/step - loss: 0.6942 - accuracy: 0.4945\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f99ceb5ca20>"]},"metadata":{"tags":[]},"execution_count":113}]},{"cell_type":"code","metadata":{"id":"LZu777HJRKio","executionInfo":{"status":"ok","timestamp":1602080709515,"user_tz":-330,"elapsed":1252,"user":{"displayName":"chetan vanapariya","photoUrl":"","userId":"09687593949013731715"}},"outputId":"40a4675b-8636-4a41-cae6-d771b89531c0","colab":{"base_uri":"https://localhost:8080/"}},"source":["history_own_data.history_data.get(\"val_accuracy\")[0:4]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[0.5024999976158142,\n"," 0.49300000071525574,\n"," 0.47350001335144043,\n"," 0.4737499952316284]"]},"metadata":{"tags":[]},"execution_count":211}]},{"cell_type":"code","metadata":{"id":"mowZM4XtvIRC","executionInfo":{"status":"ok","timestamp":1602069525081,"user_tz":-330,"elapsed":1645,"user":{"displayName":"chetan vanapariya","photoUrl":"","userId":"09687593949013731715"}},"outputId":"c0e0297f-40d5-442a-8cd0-f0322cbd9472","colab":{"base_uri":"https://localhost:8080/"}},"source":["history_own_data.history_data"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'acc': [0.5019375085830688, 0.5208125114440918, 0.6370000243186951],\n"," 'loss': [0.7112691402435303, 0.6974461674690247, 0.6364936232566833],\n"," 'val_acc': [0.5, 0.5137500166893005, 0.6667500138282776],\n"," 'val_loss': [0.69703209400177, 0.6818374395370483, 0.6041727662086487]}"]},"metadata":{"tags":[]},"execution_count":48}]},{"cell_type":"code","metadata":{"id":"SkS55uOGwqC_","executionInfo":{"status":"ok","timestamp":1602069130083,"user_tz":-330,"elapsed":1169,"user":{"displayName":"chetan vanapariya","photoUrl":"","userId":"09687593949013731715"}},"outputId":"1d274d20-c61e-45df-91df-e606fbadefaf","colab":{"base_uri":"https://localhost:8080/"}},"source":["history_own_data.history"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'acc': [None, None, None],\n"," 'loss': [0.7149479985237122, 0.6955052018165588, 0.6351665258407593],\n"," 'val_acc': [],\n"," 'val_loss': [0.6971844434738159, 0.6879738569259644, 0.6043661236763]}"]},"metadata":{"tags":[]},"execution_count":35}]},{"cell_type":"code","source":["#initial_learningrate=0.1\n","def changeLearningRate1(epoch , lr ):\n","        #print( \"---> changeLearningRate : \" , epoch )\n","        #initial_learningrate=0.01\n","        val_loss = history_own_data1.history_data.get(\"val_accuracy\")\n","        #print(lr , \"--->v_acc\" , val_loss)\n","        #lr = ( lr ) *(0.1)\n","        if ( epoch > 1):\n","          if ( (epoch % 3) == 0):\n","            lr = ( lr ) *(0.05)\n","          elif (val_loss[epoch-1] < val_loss[epoch-2]):\n","            lr = ( lr ) *(0.1)\n","        \n","        return lr"],"metadata":{"id":"HpihhgvHO_TM"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xVRP0DD1xosD","executionInfo":{"status":"ok","timestamp":1656687864476,"user_tz":-330,"elapsed":43074,"user":{"displayName":"chetan vanapariya","userId":"09687593949013731715"}},"outputId":"0b0c70b5-6a8b-46d5-f1aa-c8fe88f707d7","colab":{"base_uri":"https://localhost:8080/"}},"source":["# model-1\n","#to work with callback \n","\n","#Input layer\n","input_layer1 = Input(shape=(2,))\n","\n","initializer = tf.keras.initializers.RandomUniform(minval=0., maxval=1.)\n","#Dense hidden layer\n","layer1_1 = Dense(20,activation='tanh',kernel_initializer=initializer)(input_layer1)\n","layer1_2 = Dense(16,activation='tanh',kernel_initializer=initializer)(layer1_1)\n","layer1_3 = Dense(12,activation='tanh',kernel_initializer=initializer)(layer1_2)\n","layer1_4 = Dense(8,activation='tanh',kernel_initializer=initializer)(layer1_3)\n","layer1_5 = Dense(4,activation='tanh',kernel_initializer=initializer)(layer1_4)\n","#output layer\n","#output1 = Dense(10,activation='sigmoid',kernel_initializer=tf.keras.initializers.glorot_normal(seed=0))(layer1_5)\n","output1 = Dense(2,activation='sigmoid',kernel_initializer=tf.keras.initializers.glorot_normal(seed=0))(layer1_5)\n","\n","#Creating a model\n","model1 = Model(inputs=input_layer1,outputs=output1)\n","\n","#optimizer\n","optimizer = tf.keras.optimizers.SGD(learning_rate=0.1, momentum=0.9)\n","#optimizer_adam = tf.keras.optimizers.Adam(0.01)\n","#Callbacks\n","history_own_data1 = LossHistoryData()\n","lrschedule = tf.keras.callbacks.LearningRateScheduler( changeLearningRate1 , verbose=1)\n","f1score = F1ScoreMetrics( validation=(X_test,Y_test))\n","filepath=\"/home/weights-{epoch:02d}-{val_accuracy:.4f}.hdf5\"\n","checkpoint = ModelCheckpoint(filepath=filepath, monitor='val_loss',  verbose=1, save_best_only=True, mode='auto')\n","\n","call_back_list = [history_own_data1 , lrschedule , f1score , checkpoint]\n","#call_back_list = [history_own_data1 , f1score ]\n","\n","model1.compile(optimizer=optimizer, loss='categorical_crossentropy',metrics=['accuracy'])\n","\n","model1.fit(X_train,Y_train,epochs=10, validation_data=(X_test,Y_test), batch_size=16, callbacks= call_back_list )\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["__init__ LossHistoryData\n","validation shape 4000\n","__init__F1ScoreMetrics\n","\n","Epoch 1: LearningRateScheduler setting learning rate to 0.10000000149011612.\n","Epoch 1/10\n"," 978/1000 [============================>.] - ETA: 0s - loss: 0.7463 - accuracy: 0.4980epoch: 0\n"," — val_f1score: 0.0 -- AUC : 0.5\n","\n","Epoch 1: val_loss improved from inf to 0.72060, saving model to /home/weights-01-0.5000.hdf5\n","1000/1000 [==============================] - 4s 3ms/step - loss: 0.7464 - accuracy: 0.4981 - val_loss: 0.7206 - val_accuracy: 0.5000 - lr: 0.1000\n","\n","Epoch 2: LearningRateScheduler setting learning rate to 0.10000000149011612.\n","Epoch 2/10\n"," 997/1000 [============================>.] - ETA: 0s - loss: 0.7301 - accuracy: 0.5028epoch: 1\n"," — val_f1score: 0.0 -- AUC : 0.5\n","\n","Epoch 2: val_loss did not improve from 0.72060\n","1000/1000 [==============================] - 2s 2ms/step - loss: 0.7302 - accuracy: 0.5029 - val_loss: 0.7272 - val_accuracy: 0.5000 - lr: 0.1000\n","\n","Epoch 3: LearningRateScheduler setting learning rate to 0.10000000149011612.\n","Epoch 3/10\n"," 999/1000 [============================>.] - ETA: 0s - loss: 0.7425 - accuracy: 0.4987epoch: 2\n"," — val_f1score: 0.0 -- AUC : 0.5\n","\n","Epoch 3: val_loss improved from 0.72060 to 0.70939, saving model to /home/weights-03-0.5000.hdf5\n","1000/1000 [==============================] - 2s 2ms/step - loss: 0.7425 - accuracy: 0.4988 - val_loss: 0.7094 - val_accuracy: 0.5000 - lr: 0.1000\n","\n","Epoch 4: LearningRateScheduler setting learning rate to 0.005000000074505806.\n","Epoch 4/10\n"," 970/1000 [============================>.] - ETA: 0s - loss: 0.6999 - accuracy: 0.5001epoch: 3\n"," — val_f1score: 0.0 -- AUC : 0.5\n","\n","Epoch 4: val_loss did not improve from 0.70939\n","1000/1000 [==============================] - 3s 3ms/step - loss: 0.6995 - accuracy: 0.5020 - val_loss: 0.7146 - val_accuracy: 0.5000 - lr: 0.0050\n","\n","Epoch 5: LearningRateScheduler setting learning rate to 0.004999999888241291.\n","Epoch 5/10\n"," 976/1000 [============================>.] - ETA: 0s - loss: 0.6954 - accuracy: 0.5020epoch: 4\n"," — val_f1score: 0.0 -- AUC : 0.5\n","\n","Epoch 5: val_loss improved from 0.70939 to 0.69588, saving model to /home/weights-05-0.5000.hdf5\n","1000/1000 [==============================] - 2s 2ms/step - loss: 0.6955 - accuracy: 0.5014 - val_loss: 0.6959 - val_accuracy: 0.5000 - lr: 0.0050\n","\n","Epoch 6: LearningRateScheduler setting learning rate to 0.004999999888241291.\n","Epoch 6/10\n"," 999/1000 [============================>.] - ETA: 0s - loss: 0.6957 - accuracy: 0.4959epoch: 5\n"," — val_f1score: 0.0 -- AUC : 0.5\n","\n","Epoch 6: val_loss improved from 0.69588 to 0.69404, saving model to /home/weights-06-0.5000.hdf5\n","1000/1000 [==============================] - 2s 2ms/step - loss: 0.6957 - accuracy: 0.4960 - val_loss: 0.6940 - val_accuracy: 0.5000 - lr: 0.0050\n","\n","Epoch 7: LearningRateScheduler setting learning rate to 0.00024999999441206456.\n","Epoch 7/10\n"," 998/1000 [============================>.] - ETA: 0s - loss: 0.6935 - accuracy: 0.4957epoch: 6\n"," — val_f1score: 0.0 -- AUC : 0.5\n","\n","Epoch 7: val_loss improved from 0.69404 to 0.69316, saving model to /home/weights-07-0.5000.hdf5\n","1000/1000 [==============================] - 2s 2ms/step - loss: 0.6935 - accuracy: 0.4959 - val_loss: 0.6932 - val_accuracy: 0.5000 - lr: 2.5000e-04\n","\n","Epoch 8: LearningRateScheduler setting learning rate to 0.00024999998277053237.\n","Epoch 8/10\n"," 986/1000 [============================>.] - ETA: 0s - loss: 0.6933 - accuracy: 0.4949epoch: 7\n"," — val_f1score: 0.0 -- AUC : 0.5\n","\n","Epoch 8: val_loss did not improve from 0.69316\n","1000/1000 [==============================] - 2s 2ms/step - loss: 0.6933 - accuracy: 0.4954 - val_loss: 0.6932 - val_accuracy: 0.5000 - lr: 2.5000e-04\n","\n","Epoch 9: LearningRateScheduler setting learning rate to 0.00024999998277053237.\n","Epoch 9/10\n"," 992/1000 [============================>.] - ETA: 0s - loss: 0.6933 - accuracy: 0.4940epoch: 8\n"," — val_f1score: 0.0 -- AUC : 0.5\n","\n","Epoch 9: val_loss improved from 0.69316 to 0.69315, saving model to /home/weights-09-0.5000.hdf5\n","1000/1000 [==============================] - 2s 2ms/step - loss: 0.6933 - accuracy: 0.4941 - val_loss: 0.6932 - val_accuracy: 0.5000 - lr: 2.5000e-04\n","\n","Epoch 10: LearningRateScheduler setting learning rate to 1.2499999138526619e-05.\n","Epoch 10/10\n"," 979/1000 [============================>.] - ETA: 0s - loss: 0.6932 - accuracy: 0.5004epoch: 9\n"," — val_f1score: 0.0 -- AUC : 0.5\n","\n","Epoch 10: val_loss did not improve from 0.69315\n","1000/1000 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.5001 - val_loss: 0.6932 - val_accuracy: 0.5000 - lr: 1.2500e-05\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f714eb6e890>"]},"metadata":{},"execution_count":40}]},{"cell_type":"code","source":["#initial_learningrate=0.1\n","def changeLearningRate2(epoch , lr ):\n","        #print( \"---> changeLearningRate : \" , epoch )\n","        #initial_learningrate=0.01\n","        val_loss = history_own_data2.history_data.get(\"val_accuracy\")\n","        #print(lr , \"--->v_acc\" , val_loss)\n","        #lr = ( lr ) *(0.1)\n","        if ( epoch > 1):\n","          if ( (epoch % 3) == 0):\n","            lr = ( lr ) *(0.05)\n","          elif (val_loss[epoch-1] < val_loss[epoch-2]):\n","            lr = ( lr ) *(0.1)\n","        \n","        return lr"],"metadata":{"id":"5v8tBRe6TrnO"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jO_6SYrE0tdy","executionInfo":{"status":"ok","timestamp":1656688417602,"user_tz":-330,"elapsed":11706,"user":{"displayName":"chetan vanapariya","userId":"09687593949013731715"}},"outputId":"7d134375-cb90-443c-cb33-a7e17e56ab84","colab":{"base_uri":"https://localhost:8080/"}},"source":["# model-2\n","#to work with callback\n","\n","#Input layer\n","input_layer2 = Input(shape=(2,))\n","\n","#initializer = tf.keras.initializers.he_uniform()\n","initializer =  tf.keras.initializers.RandomUniform(minval=0., maxval=1.)\n","\n","#Dense hidden layer\n","layer2_1 = Dense(16,activation='relu',kernel_initializer=tf.keras.initializers.RandomUniform(minval=0., maxval=1.))(input_layer2)\n","layer2_2 = Dense(32,activation='relu',kernel_initializer=tf.keras.initializers.RandomUniform(minval=0., maxval=1.))(layer2_1)\n","layer2_3 = Dense(16,activation='relu',kernel_initializer=tf.keras.initializers.RandomUniform(minval=0., maxval=1.))(layer2_2)\n","layer2_4 = Dense(8,activation='relu',kernel_initializer=tf.keras.initializers.RandomUniform(minval=0., maxval=1.))(layer2_3)\n","layer2_5 = Dense(4,activation='relu',kernel_initializer=tf.keras.initializers.RandomUniform(minval=0., maxval=1.))(layer2_4)\n","#output layer\n","#output2 = Dense(10,activation='sigmoid',kernel_initializer=tf.keras.initializers.glorot_normal(seed=0))(layer2_5)\n","output2 = Dense(2,activation='sigmoid',kernel_initializer=tf.keras.initializers.glorot_normal(seed=0))(layer2_5)\n","#Creating a model\n","model2 = Model(inputs=input_layer2,outputs=output2)\n","\n","#optimizer\n","optimizer2 = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9)\n","#Callbacks\n","history_own_data2 = LossHistoryData()\n","lrschedule = tf.keras.callbacks.LearningRateScheduler( changeLearningRate2 , verbose=1)\n","f1score = F1ScoreMetrics( validation=(X_test,Y_test))\n","filepath=\"/home/weights-{epoch:02d}-{val_accuracy:.4f}.hdf5\"\n","checkpoint = ModelCheckpoint(filepath=filepath, monitor='val_loss',  verbose=1, save_best_only=True, mode='auto')\n","\n","call_back_list = [history_own_data2 , lrschedule , f1score , checkpoint ]\n","\n","model2.compile(optimizer=optimizer2 , loss='categorical_crossentropy',metrics=['accuracy'])\n","\n","model2.fit(X_train,Y_train,epochs=3, validation_data=(X_test,Y_test), batch_size=16, callbacks= call_back_list )\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["__init__ LossHistoryData\n","validation shape 4000\n","__init__F1ScoreMetrics\n","\n","Epoch 1: LearningRateScheduler setting learning rate to 0.009999999776482582.\n","Epoch 1/3\n"," 991/1000 [============================>.] - ETA: 0s - loss: 2.8816 - accuracy: 0.5050epoch: 0\n"," — val_f1score: 0.5 -- AUC : 0.5\n","\n","Epoch 1: val_loss improved from inf to 0.69604, saving model to /home/weights-01-0.5000.hdf5\n","1000/1000 [==============================] - 3s 3ms/step - loss: 2.8619 - accuracy: 0.5057 - val_loss: 0.6960 - val_accuracy: 0.5000 - lr: 0.0100\n","\n","Epoch 2: LearningRateScheduler setting learning rate to 0.009999999776482582.\n","Epoch 2/3\n"," 986/1000 [============================>.] - ETA: 0s - loss: 0.6940 - accuracy: 0.4963epoch: 1\n"," — val_f1score: 0.5 -- AUC : 0.5\n","\n","Epoch 2: val_loss improved from 0.69604 to 0.69391, saving model to /home/weights-02-0.5000.hdf5\n","1000/1000 [==============================] - 2s 2ms/step - loss: 0.6940 - accuracy: 0.4966 - val_loss: 0.6939 - val_accuracy: 0.5000 - lr: 0.0100\n","\n","Epoch 3: LearningRateScheduler setting learning rate to 0.009999999776482582.\n","Epoch 3/3\n"," 973/1000 [============================>.] - ETA: 0s - loss: 0.6939 - accuracy: 0.5000epoch: 2\n"," — val_f1score: 0.5 -- AUC : 0.5\n","\n","Epoch 3: val_loss did not improve from 0.69391\n","1000/1000 [==============================] - 2s 2ms/step - loss: 0.6939 - accuracy: 0.5008 - val_loss: 0.6957 - val_accuracy: 0.5000 - lr: 0.0100\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f713f525f90>"]},"metadata":{},"execution_count":44}]},{"cell_type":"code","source":["#initial_learningrate=0.1\n","def changeLearningRate3(epoch , lr ):\n","        #print( \"---> changeLearningRate : \" , epoch )\n","        #initial_learningrate=0.01\n","        val_loss = history_own_data3.history_data.get(\"val_accuracy\")\n","        #print(lr , \"--->v_acc\" , val_loss)\n","        #lr = ( lr ) *(0.1)\n","        if ( epoch > 1):\n","          if ( (epoch % 3) == 0):\n","            lr = ( lr ) *(0.05)\n","          elif (val_loss[epoch-1] < val_loss[epoch-2]):\n","            lr = ( lr ) *(0.1)\n","        \n","        return lr"],"metadata":{"id":"8vpVcyOUVTo2"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"At_ge30l2nc9","executionInfo":{"status":"ok","timestamp":1656688685012,"user_tz":-330,"elapsed":11882,"user":{"displayName":"chetan vanapariya","userId":"09687593949013731715"}},"outputId":"77ecdd2e-c70e-4da7-d299-ffb0568406a9","colab":{"base_uri":"https://localhost:8080/"}},"source":["# model-3\n","#to work with callback\n","\n","#Input layer\n","input_layer3 = Input(shape=(2,))\n","\n","initializer = tf.keras.initializers.he_uniform()\n","#Dense hidden layer\n","layer3_1 = Dense(30,activation='relu',kernel_initializer=initializer)(input_layer3)\n","layer3_2 = Dense(40,activation='relu',kernel_initializer=initializer)(layer3_1)\n","layer3_3 = Dense(30,activation='relu',kernel_initializer=initializer)(layer3_2)\n","layer3_4 = Dense(20,activation='relu',kernel_initializer=initializer)(layer3_3)\n","layer3_5 = Dense(10,activation='relu',kernel_initializer=initializer)(layer3_4)\n","#output layer\n","output3 = Dense(2,activation='sigmoid',kernel_initializer=tf.keras.initializers.glorot_normal(seed=0))(layer3_5)\n","#Creating a model\n","model3 = Model(inputs=input_layer3,outputs=output3)\n","\n","#optimizer\n","optimizer = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9)\n","#Callbacks\n","history_own_data3 = LossHistoryData()\n","lrschedule = tf.keras.callbacks.LearningRateScheduler( changeLearningRate3 , verbose=1)\n","f1score = F1ScoreMetrics( validation=(X_test,Y_test))\n","filepath=\"/home/model_save/weights-{epoch:02d}-{val_accuracy:.4f}.hdf5\"\n","checkpoint = ModelCheckpoint(filepath=filepath, monitor='val_loss',  verbose=1, save_best_only=True, mode='auto')\n","\n","call_back_list = [history_own_data3 , lrschedule , f1score , checkpoint ]\n","\n","model3.compile(optimizer=optimizer, loss='categorical_crossentropy',metrics=['accuracy'])\n","\n","model3.fit(X_train,Y_train,epochs=3, validation_data=(X_test,Y_test), batch_size=16, callbacks= call_back_list )\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["__init__ LossHistoryData\n","validation shape 4000\n","__init__F1ScoreMetrics\n","\n","Epoch 1: LearningRateScheduler setting learning rate to 0.009999999776482582.\n","Epoch 1/3\n","   1/1000 [..............................] - ETA: 12:53 - loss: 1.7291 - accuracy: 0.5625WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0015s vs `on_train_batch_end` time: 0.0016s). Check your callbacks.\n"," 976/1000 [============================>.] - ETA: 0s - loss: 0.6379 - accuracy: 0.6391epoch: 0\n"," — val_f1score: 0.3134872417982989 -- AUC : 0.57625\n","\n","Epoch 1: val_loss improved from inf to 0.62453, saving model to /home/model_save/weights-01-0.6585.hdf5\n","1000/1000 [==============================] - 5s 4ms/step - loss: 0.6378 - accuracy: 0.6395 - val_loss: 0.6245 - val_accuracy: 0.6585 - lr: 0.0100\n","\n","Epoch 2: LearningRateScheduler setting learning rate to 0.009999999776482582.\n","Epoch 2/3\n"," 991/1000 [============================>.] - ETA: 0s - loss: 0.6168 - accuracy: 0.6609epoch: 1\n"," — val_f1score: 0.30837181288897814 -- AUC : 0.569375\n","\n","Epoch 2: val_loss improved from 0.62453 to 0.59708, saving model to /home/model_save/weights-02-0.6737.hdf5\n","1000/1000 [==============================] - 2s 2ms/step - loss: 0.6175 - accuracy: 0.6606 - val_loss: 0.5971 - val_accuracy: 0.6737 - lr: 0.0100\n","\n","Epoch 3: LearningRateScheduler setting learning rate to 0.009999999776482582.\n","Epoch 3/3\n"," 997/1000 [============================>.] - ETA: 0s - loss: 0.6111 - accuracy: 0.6654epoch: 2\n"," — val_f1score: 0.5042072265302755 -- AUC : 0.624375\n","\n","Epoch 3: val_loss did not improve from 0.59708\n","1000/1000 [==============================] - 2s 2ms/step - loss: 0.6108 - accuracy: 0.6656 - val_loss: 0.6065 - val_accuracy: 0.6660 - lr: 0.0100\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f713fe4f610>"]},"metadata":{},"execution_count":48}]},{"cell_type":"code","source":["# model-4\n","#to work with callback\n","\n","#Input layer\n","input_layer4 = Input(shape=(2,))\n","\n","initializer = tf.keras.initializers.he_uniform()\n","#Dense hidden layer\n","layer4_1 = Dense(100,activation='relu',kernel_initializer=initializer)(input_layer4)\n","layer4_2 = Dense(64,activation='relu',kernel_initializer=initializer)(layer4_1)\n","layer4_3 = Dense(32,activation='relu',kernel_initializer=initializer)(layer4_2)\n","layer4_4 = Dense(8,activation='relu',kernel_initializer=initializer)(layer4_3)\n","layer4_5 = Dense(4,activation='relu',kernel_initializer=initializer)(layer4_4)\n","#output layer\n","output4 = Dense(2,activation='softmax',kernel_initializer=tf.keras.initializers.glorot_normal(seed=0))(layer4_5)\n","#Creating a model\n","model4 = Model(inputs=input_layer4,outputs=output4)\n","\n","#optimizer\n","#optimizer = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9)\n","##optimizer_adam = tf.keras.optimizers.Adam(0.01)\n","#Callbacks\n","history_own_data4 = LossHistoryData()\n","lrschedule = tf.keras.callbacks.LearningRateScheduler( history_own_data4.changeLearningRate4 , verbose=1)\n","f1score = F1ScoreMetrics( validation=(X_test,Y_test))\n","filepath=\"/home/model_save/weights-{epoch:02d}-{val_accuracy:.4f}.hdf5\"\n","checkpoint = ModelCheckpoint(filepath=filepath, monitor='val_loss',  verbose=1, save_best_only=True, mode='auto')\n","\n","call_back_list = [history_own_data4 , lrschedule , f1score , checkpoint ]\n","\n","model4.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['accuracy'])\n","\n","model4.fit(X_train,Y_train,epochs=10, validation_data=(X_test,Y_test), batch_size=16, callbacks= call_back_list )\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wjQetx__WCkQ","executionInfo":{"status":"ok","timestamp":1656689765282,"user_tz":-330,"elapsed":32177,"user":{"displayName":"chetan vanapariya","userId":"09687593949013731715"}},"outputId":"eaf5a2c8-1a34-430f-b661-b58ad6a8453d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["__init__ LossHistoryData\n","validation shape 4000\n","__init__F1ScoreMetrics\n","\n","Epoch 1: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n","Epoch 1/10\n"," 988/1000 [============================>.] - ETA: 0s - loss: 0.6651 - accuracy: 0.5998epoch: 0\n"," — val_f1score: 0.66125 -- AUC : 0.6612499999999999\n","\n","Epoch 1: val_loss improved from inf to 0.62278, saving model to /home/model_save/weights-01-0.6612.hdf5\n","1000/1000 [==============================] - 4s 3ms/step - loss: 0.6647 - accuracy: 0.5999 - val_loss: 0.6228 - val_accuracy: 0.6612 - lr: 0.0010\n","\n","Epoch 2: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n","Epoch 2/10\n"," 994/1000 [============================>.] - ETA: 0s - loss: 0.6169 - accuracy: 0.6634epoch: 1\n"," — val_f1score: 0.66425 -- AUC : 0.66425\n","\n","Epoch 2: val_loss improved from 0.62278 to 0.60193, saving model to /home/model_save/weights-02-0.6643.hdf5\n","1000/1000 [==============================] - 3s 3ms/step - loss: 0.6168 - accuracy: 0.6633 - val_loss: 0.6019 - val_accuracy: 0.6643 - lr: 0.0010\n","\n","Epoch 3: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n","Epoch 3/10\n"," 984/1000 [============================>.] - ETA: 0s - loss: 0.6078 - accuracy: 0.6664epoch: 2\n"," — val_f1score: 0.665 -- AUC : 0.665\n","\n","Epoch 3: val_loss did not improve from 0.60193\n","1000/1000 [==============================] - 3s 3ms/step - loss: 0.6082 - accuracy: 0.6657 - val_loss: 0.6033 - val_accuracy: 0.6650 - lr: 0.0010\n","\n","Epoch 4: LearningRateScheduler setting learning rate to 5.0000002374872565e-05.\n","Epoch 4/10\n"," 987/1000 [============================>.] - ETA: 0s - loss: 0.6016 - accuracy: 0.6710epoch: 3\n"," — val_f1score: 0.67325 -- AUC : 0.67325\n","\n","Epoch 4: val_loss improved from 0.60193 to 0.59442, saving model to /home/model_save/weights-04-0.6733.hdf5\n","1000/1000 [==============================] - 3s 3ms/step - loss: 0.6013 - accuracy: 0.6712 - val_loss: 0.5944 - val_accuracy: 0.6733 - lr: 5.0000e-05\n","\n","Epoch 5: LearningRateScheduler setting learning rate to 5.0000002374872565e-05.\n","Epoch 5/10\n"," 996/1000 [============================>.] - ETA: 0s - loss: 0.6004 - accuracy: 0.6723epoch: 4\n"," — val_f1score: 0.67375 -- AUC : 0.6737500000000001\n","\n","Epoch 5: val_loss improved from 0.59442 to 0.59388, saving model to /home/model_save/weights-05-0.6737.hdf5\n","1000/1000 [==============================] - 3s 3ms/step - loss: 0.6004 - accuracy: 0.6722 - val_loss: 0.5939 - val_accuracy: 0.6737 - lr: 5.0000e-05\n","\n","Epoch 6: LearningRateScheduler setting learning rate to 5.0000002374872565e-05.\n","Epoch 6/10\n"," 994/1000 [============================>.] - ETA: 0s - loss: 0.6001 - accuracy: 0.6722epoch: 5\n"," — val_f1score: 0.67475 -- AUC : 0.67475\n","\n","Epoch 6: val_loss improved from 0.59388 to 0.59291, saving model to /home/model_save/weights-06-0.6747.hdf5\n","1000/1000 [==============================] - 3s 3ms/step - loss: 0.6001 - accuracy: 0.6720 - val_loss: 0.5929 - val_accuracy: 0.6747 - lr: 5.0000e-05\n","\n","Epoch 7: LearningRateScheduler setting learning rate to 2.5000001187436284e-06.\n","Epoch 7/10\n"," 999/1000 [============================>.] - ETA: 0s - loss: 0.5999 - accuracy: 0.6731epoch: 6\n"," — val_f1score: 0.674 -- AUC : 0.6739999999999999\n","\n","Epoch 7: val_loss did not improve from 0.59291\n","1000/1000 [==============================] - 3s 3ms/step - loss: 0.5999 - accuracy: 0.6731 - val_loss: 0.5930 - val_accuracy: 0.6740 - lr: 2.5000e-06\n","\n","Epoch 8: LearningRateScheduler setting learning rate to 2.500000164218363e-07.\n","Epoch 8/10\n"," 989/1000 [============================>.] - ETA: 0s - loss: 0.5997 - accuracy: 0.6733epoch: 7\n"," — val_f1score: 0.674 -- AUC : 0.6739999999999999\n","\n","Epoch 8: val_loss did not improve from 0.59291\n","1000/1000 [==============================] - 3s 3ms/step - loss: 0.5998 - accuracy: 0.6734 - val_loss: 0.5930 - val_accuracy: 0.6740 - lr: 2.5000e-07\n","\n","Epoch 9: LearningRateScheduler setting learning rate to 2.500000277905201e-07.\n","Epoch 9/10\n"," 986/1000 [============================>.] - ETA: 0s - loss: 0.5992 - accuracy: 0.6745epoch: 8\n"," — val_f1score: 0.674 -- AUC : 0.6739999999999999\n","\n","Epoch 9: val_loss did not improve from 0.59291\n","1000/1000 [==============================] - 3s 3ms/step - loss: 0.5998 - accuracy: 0.6736 - val_loss: 0.5930 - val_accuracy: 0.6740 - lr: 2.5000e-07\n","\n","Epoch 10: LearningRateScheduler setting learning rate to 1.2500001389526006e-08.\n","Epoch 10/10\n"," 993/1000 [============================>.] - ETA: 0s - loss: 0.5999 - accuracy: 0.6735epoch: 9\n"," — val_f1score: 0.674 -- AUC : 0.6739999999999999\n","\n","Epoch 10: val_loss did not improve from 0.59291\n","1000/1000 [==============================] - 3s 3ms/step - loss: 0.5997 - accuracy: 0.6736 - val_loss: 0.5930 - val_accuracy: 0.6740 - lr: 1.2500e-08\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f713e3f38d0>"]},"metadata":{},"execution_count":57}]}]}